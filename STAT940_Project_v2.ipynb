{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgBFjTbqa8dz",
        "outputId": "0a9c31c7-487c-42a8-9aaa-54b017eee391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CcHGEyVJ4g7w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "import re\n",
        "import hashlib\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import enum\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import logging\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsRjxq34Z7ow"
      },
      "source": [
        "## Part 1: Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLhqwF73gWYp",
        "outputId": "b9bc418c-644c-4fde-d245-137ca9a5e39f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 748/748 [00:10<00:00, 68.60it/s] \n",
            "100%|██████████| 162/162 [00:01<00:00, 96.44it/s] \n",
            "100%|██████████| 161/161 [00:01<00:00, 102.40it/s]\n"
          ]
        }
      ],
      "source": [
        "def merge_jsons(folder_path, output_path):\n",
        "    jsons = []\n",
        "    # list to hold contents of jsons\n",
        "    for filename in tqdm(os.listdir(folder_path)):\n",
        "        if filename.endswith('.json'):  # Process only JSON files\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            with open(file_path, 'r') as file:\n",
        "                # load json\n",
        "                data = json.load(file)\n",
        "                jsons.append(json.dumps(data))\n",
        "\n",
        "    # combine all jsosn into string\n",
        "    output_content = ',\\n'.join(jsons)\n",
        "    output_content = f\"{output_content}\"\n",
        "\n",
        "    # save combined json\n",
        "    with open(output_path, 'w') as output_file:\n",
        "        output_file.write(output_content)\n",
        "\n",
        "train_folder_path = '/content/drive/MyDrive/Final Project Datasets/data_symbolic_regression/train'\n",
        "train_output_path = '/content/train_merged.json'\n",
        "test_folder_path = '/content/drive/MyDrive/Final Project Datasets/data_symbolic_regression/test'\n",
        "test_output_path = '/content/test_merged.json'\n",
        "val_folder_path = '/content/drive/MyDrive/Final Project Datasets/data_symbolic_regression/val'\n",
        "val_output_path = '/content/val_merged.json'\n",
        "\n",
        "# merge the jsons together because\n",
        "merge_jsons(train_folder_path, train_output_path)\n",
        "merge_jsons(test_folder_path, test_output_path)\n",
        "merge_jsons(val_folder_path, val_output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Reajpkyw_22c"
      },
      "source": [
        "## 2. Embed the formula"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y1qcS67birAR",
        "outputId": "4f582a16-2309-4644-f15d-aa7ecbacc4b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['add(reverse(add(var_0, var_1), N(N, N)), pow_2(gaussian(var_2, N), N(N, N)))',\n",
            " 'mult(neg(add(var_2, var_0), N(N, N)), gaussian(sin(var_1, N), N(N, N)))',\n",
            " 'mult(tanh(log(var_2, N), N(N, N)), sqrt(mult(var_0, var_1), N(N, N)))',\n",
            " 'mult(add(add(var_1, var_0), mult(var_0, var_2)), cos(reverse(var_2, N), N(N, '\n",
            " 'N)))',\n",
            " 'add(mult(var_2(N, N), add(var_1, var_0)), add(exp(var_2, N), sin(var_2, N)))']\n"
          ]
        }
      ],
      "source": [
        "merged_json_path = '/content/train_merged.json'\n",
        "\n",
        "unique_formulas = set()\n",
        "\n",
        "with open(merged_json_path, 'r') as file:\n",
        "        # Read the file line by line\n",
        "        for line in file:\n",
        "            # Remove trailing commas and whitespace\n",
        "            line = line.strip().rstrip(',')\n",
        "\n",
        "            # Parse the line as a JSON object\n",
        "            if line:  # Skip empty lines\n",
        "                try:\n",
        "                    data = json.loads(line)\n",
        "                    if 'formula' in data:\n",
        "                        unique_formulas.add(data['formula'])\n",
        "                except json.JSONDecodeError as e:\n",
        "                    print(f\"Error decoding line: {line}\\n{e}\")\n",
        "# unique formulas\n",
        "unique_formulas = list(unique_formulas)\n",
        "pprint(unique_formulas[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qylRTy4jyep",
        "outputId": "52c5d85f-f1b9-44b8-d413-41941b07cf70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: ['C_0', 'C_1', 'C_2', 'N', 'add', 'cos', 'cosh', 'exp', 'gaussian', 'log', 'mult', 'neg', 'pow_2', 'reverse', 'sin', 'sinh', 'sqrt', 'tan', 'tanh', 'var_0', 'var_1', 'var_2']\n"
          ]
        }
      ],
      "source": [
        "# function to extract tokens from a formula\n",
        "def extract_tokens(formulas):\n",
        "    tokens = set()\n",
        "    for formula in formulas:\n",
        "        tokens.update(re.findall(r\"[a-zA-Z_]\\w*\", formula))\n",
        "    return sorted(tokens)\n",
        "\n",
        "# generate vocabulary\n",
        "vocabulary = extract_tokens(unique_formulas)\n",
        "print(\"Vocabulary:\", vocabulary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kA_EBOaAYFE"
      },
      "source": [
        "Here I made a lookup table of the equations, later I'll add the equations from the training and validation set so that no possible equations are left out. Maybe we can look for a better way to embed the equations later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvnLSTjO33W5"
      },
      "outputs": [],
      "source": [
        "equation_to_index = {eq: idx for idx, eq in enumerate(unique_formulas)}\n",
        "index_to_equation = {idx: eq for eq, idx in equation_to_index.items()}\n",
        "\n",
        "num_equations = len(unique_formulas)\n",
        "embedding_dim = 128  # embedding dimension\n",
        "\n",
        "# embedding layer\n",
        "equation_embeddings = nn.Embedding(num_equations, embedding_dim)\n",
        "\n",
        "# get the embedding of an equation\n",
        "def get_embedding(equation):\n",
        "    index = torch.tensor([equation_to_index[equation]])\n",
        "    embedding = equation_embeddings(index)\n",
        "    return embedding.squeeze(0)\n",
        "\n",
        "# to map back from embedding to equation (since embeddings are unique)\n",
        "def find_equation(embedding):\n",
        "    # create a lookup table\n",
        "    all_embeddings = equation_embeddings.weight.detach()\n",
        "    distances = torch.norm(all_embeddings - embedding, dim=1)\n",
        "    closest_index = torch.argmin(distances).item()\n",
        "    return index_to_equation[closest_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKmZaybz4A4-",
        "outputId": "0fa5d528-2d62-49a7-d25c-edfee00e365b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "add(reverse(add(var_0, var_1), N(N, N)), pow_2(gaussian(var_2, N), N(N, N)))\n",
            "tensor([-0.3946,  0.1830, -1.0884,  1.2600,  0.7928, -0.0539, -1.7674, -0.1835,\n",
            "         0.2262,  0.9387,  0.7711,  0.3016,  0.5474, -0.2554, -0.5215, -0.8206,\n",
            "        -0.8534, -1.2935,  2.0319, -1.5475, -1.9659, -0.1956, -2.3791,  1.1743,\n",
            "        -0.2868, -0.7389, -0.1031,  0.3432, -0.0188, -0.9699,  1.2216,  0.8068,\n",
            "         1.0104, -0.7242, -0.6620,  0.4117,  0.1672, -0.6343, -0.0741, -0.0933,\n",
            "         0.5829,  2.3026, -0.4869,  0.3249, -0.4862, -1.7047,  0.2021,  0.1226,\n",
            "        -1.0994,  0.7298,  0.5654, -1.3898,  0.3802,  1.2605,  0.0468,  1.6981,\n",
            "         1.1107,  0.4145, -3.0917,  0.2704,  0.8779, -1.4970, -0.4732, -0.1609,\n",
            "         0.2005, -1.6813, -1.6167, -0.0865, -0.2743,  0.0910, -0.3590, -0.6032,\n",
            "         0.3152, -1.7461, -0.1941,  1.7870, -1.4460, -0.1972, -0.6773, -0.0979,\n",
            "         0.4613, -0.0040, -0.2972, -0.0202, -1.0078,  0.8548, -0.8433,  0.1967,\n",
            "         1.4513,  0.7051,  0.2668, -1.4893, -0.5274,  0.0490, -1.4610, -0.0115,\n",
            "        -0.9984,  1.4126, -0.8770, -0.6430,  0.9435, -0.9188,  2.1574,  1.0631,\n",
            "         0.2599,  0.7420, -0.0873,  1.8935,  0.8255, -2.2076,  1.7992, -0.1866,\n",
            "         0.7558,  1.5485, -0.1067,  0.1422, -0.1132,  0.2792,  2.3139, -0.3353,\n",
            "        -1.6763,  0.4156,  0.4462, -0.0476,  0.2030, -0.8810, -1.2745, -0.1510],\n",
            "       grad_fn=<SqueezeBackward1>)\n",
            "add(reverse(add(var_0, var_1), N(N, N)), pow_2(gaussian(var_2, N), N(N, N)))\n"
          ]
        }
      ],
      "source": [
        "print(unique_formulas[0])\n",
        "print(get_embedding(unique_formulas[0]))\n",
        "print(find_equation(get_embedding(unique_formulas[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ceREQ8p4kBX"
      },
      "source": [
        "## 3. Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qI26w1f4mOX"
      },
      "outputs": [],
      "source": [
        "class EquationDataset(Dataset):\n",
        "    def __init__(self, data_point):\n",
        "        self.formula = data_point[\"formula\"]\n",
        "        self.formula_human_readable = data_point[\"formula_human_readable\"]\n",
        "        self.formula_depth = data_point[\"formula_depth\"]\n",
        "        self.n_vars = data_point[\"n_vars\"]\n",
        "        self.n_consts = data_point[\"n_consts\"]\n",
        "        self.n_points = data_point[\"n_points\"]\n",
        "        self.var_bound_dict = data_point[\"var_bound_dict\"]\n",
        "        self.const_value_dict = data_point[\"const_value_dict\"]\n",
        "        self.meta_list = data_point[\"meta_list\"]\n",
        "        self.points = data_point[\"points\"]\n",
        "        self.target = data_point[\"target\"]\n",
        "\n",
        "        self. embedded_formula = get_embedding(self.formula)\n",
        "\n",
        "        # add code here to use the pre-trained t-net to embed the points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVHCrTY6hXlU"
      },
      "source": [
        "## 4. Gaussian Diffusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxYiVP2rjMD9"
      },
      "source": [
        "### 1. Noise Schedulers\n",
        "\n",
        "I haven't tried integrating these yet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3yvhKshpM-Ux"
      },
      "outputs": [],
      "source": [
        "# taken from Diffusion-LM code and somewhat adapted\n",
        "# remember to properly reference later\n",
        "\n",
        "def betas_for_alpha_bar(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n",
        "    betas = []\n",
        "    for i in range(num_diffusion_timesteps):\n",
        "        t1 = i / num_diffusion_timesteps\n",
        "        t2 = (i + 1) / num_diffusion_timesteps\n",
        "        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n",
        "    return np.array(betas)\n",
        "\n",
        "def betas_for_alpha_bar2(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n",
        "    betas = []\n",
        "    betas.append(min(1-alpha_bar(0), max_beta))\n",
        "    for i in range(num_diffusion_timesteps-1):\n",
        "        t1 = i / num_diffusion_timesteps\n",
        "        t2 = (i + 1) / num_diffusion_timesteps\n",
        "        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n",
        "    return np.array(betas)\n",
        "\n",
        "def get_beta_schedule(beta_schedule, num_diffusion_timesteps):\n",
        "    # original beta scheduler from Ho et al\n",
        "    if beta_schedule == \"linear\":\n",
        "        scale = 1000 / num_diffusion_timesteps\n",
        "        beta_start = scale * 0.0001\n",
        "        beta_end = scale * 0.02\n",
        "        return np.linspace(\n",
        "            beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64\n",
        "        )\n",
        "\n",
        "    elif beta_schedule == \"cosine\":\n",
        "        return betas_for_alpha_bar(\n",
        "            num_diffusion_timesteps,\n",
        "            lambda t: math.cos((t + 0.008) / 1.008 * math.pi / 2) ** 2,\n",
        "        )\n",
        "\n",
        "    elif beta_schedule == 'sqrt':\n",
        "        return betas_for_alpha_bar(\n",
        "            num_diffusion_timesteps,\n",
        "            lambda t: 1-np.sqrt(t + 0.0001),\n",
        "        )\n",
        "\n",
        "    elif beta_schedule == 'trunc_cos':\n",
        "        return betas_for_alpha_bar2(\n",
        "            num_diffusion_timesteps,\n",
        "            lambda t: np.cos((t + 0.1) / 1.1 * np.pi / 2) ** 2,\n",
        "        )\n",
        "\n",
        "    elif beta_schedule == 'trunc_lin':\n",
        "        scale = 1000 / num_diffusion_timesteps\n",
        "        beta_start = scale * 0.0001 + 0.01\n",
        "        beta_end = scale * 0.02 + 0.01\n",
        "        return np.linspace(\n",
        "            beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64\n",
        "        )\n",
        "\n",
        "    elif beta_schedule == 'pw_linear':\n",
        "        scale = 1000 / num_diffusion_timesteps\n",
        "        beta_start = scale * 0.0001 + 0.01\n",
        "        beta_mid = scale * 0.0001  #scale * 0.02\n",
        "        beta_end = scale * 0.02\n",
        "        first_part = np.linspace(\n",
        "            beta_start, beta_mid, 10, dtype=np.float64\n",
        "        )\n",
        "        second_part = np.linspace(\n",
        "            beta_mid, beta_end, num_diffusion_timesteps - 10 , dtype=np.float64\n",
        "        )\n",
        "        return np.concatenate(\n",
        "            [first_part, second_part]\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError(f\"unknown beta schedule: {beta_schedule}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AinRezcmr3P"
      },
      "source": [
        "### 2. Timestep embeddings\n",
        "\n",
        "Function for timestep embeddings. Timesteps represent the progression of noise addition or removal during the forward or reverse diffusion process. Here I'm using sinusoidal timestep embeddings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def timestep_embedding(timesteps, embedding_dim):\n",
        "    \"\"\"\n",
        "    Create sinusoidal timestep embeddings\n",
        "\n",
        "    Args:\n",
        "        timesteps (torch.Tensor): A tensor containing timestep values.\n",
        "        embedding_dim (int): The size of the embedding vector.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A tensor containing the sinusoidal timestep embeddings.\n",
        "    \"\"\"\n",
        "    # Get the device where the timesteps tensor resides\n",
        "    device = timesteps.device\n",
        "    # Compute half the embedding dimension\n",
        "    half_dim = embedding_dim // 2\n",
        "    # Compute the scaling factor for the sinusoidal frequencies\n",
        "    emb = math.log(10000) / (half_dim - 1)\n",
        "    # Generate the frequency values for the embeddings\n",
        "    emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "    # Scale the timesteps by the frequency values\n",
        "    emb = timesteps.float().unsqueeze(1) * emb.unsqueeze(0)\n",
        "    # Concatenate sine and cosine components of the embeddings\n",
        "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
        "    return emb\n",
        "\n",
        "\n",
        "class TimestepBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A base class for modules that accept timestep embeddings.\n",
        "    \"\"\"\n",
        "    def forward(self, x, t_emb):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class TimestepEmbedSequential(nn.Sequential, TimestepBlock):\n",
        "    \"\"\"\n",
        "    A sequential module that passes timestep embeddings to the children that\n",
        "    support it as an extra input.\n",
        "    \"\"\"\n",
        "    def forward(self, x, t_emb):\n",
        "        for layer in self:\n",
        "            if isinstance(layer, TimestepBlock):\n",
        "                x = layer(x, t_emb)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8_64-IfJYCCw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. U-Net\n",
        "\n",
        "U-net implementation for diffusion"
      ],
      "metadata": {
        "id": "2xJU6320voTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(TimestepBlock):\n",
        "    \"\"\"\n",
        "    A Residual Block that supports timestep embeddings.\n",
        "\n",
        "    :param in_clannels: the number of input channels\n",
        "    :param out_channels: the number of output channels\n",
        "    :param time_emb_dim: the dimension of the timestep embedding\n",
        "    :param dropout: the dropout rate\n",
        "    :param use_conv: whether to use a convolutional shortcut\n",
        "\n",
        "    This block:\n",
        "    - Applies normalization, activation, and convolution to the input.\n",
        "    - Adds the effect of timestep embeddings.\n",
        "    - Includes a residual connection, with an optional convolution for channel alignment.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, time_emb_dim, dropout=0.0, use_conv=False):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.use_conv = use_conv\n",
        "\n",
        "        # Normalization and activation for the first layer\n",
        "        self.norm1 = nn.GroupNorm(32, in_channels)\n",
        "        self.activation1 = nn.SiLU()\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "\n",
        "        # Time embedding transformation\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_emb_dim, out_channels),\n",
        "        )\n",
        "\n",
        "        # Normalization, activation, and convolution for the second layer\n",
        "        self.norm2 = nn.GroupNorm(32, out_channels)\n",
        "        self.activation2 = nn.SiLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "\n",
        "        # Shortcut connection to align input and output channels\n",
        "        if in_channels != out_channels:\n",
        "            if use_conv:\n",
        "                self.shortcut = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "            else:\n",
        "                self.shortcut = nn.Conv1d(in_channels, out_channels, kernel_size=1)\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "    def forward(self, x, t_emb):\n",
        "        \"\"\"\n",
        "        Forward pass for the Residual Block.\n",
        "\n",
        "        :param x: Input tensor.\n",
        "        :param t_emb: Timestep embeddings.\n",
        "\n",
        "        :return: Output tensor after residual connections.\n",
        "        \"\"\"\n",
        "        # First convolution block\n",
        "        h = self.norm1(x)\n",
        "        h = self.activation1(h)\n",
        "        h = self.conv1(h)\n",
        "\n",
        "        # Add timestep embedding\n",
        "        t_emb = self.time_mlp(t_emb).unsqueeze(-1) # Match dimensions for addition\n",
        "        h = h + t_emb\n",
        "\n",
        "        # Second convolution block\n",
        "        h = self.norm2(h)\n",
        "        h = self.activation2(h)\n",
        "        h = self.dropout(h)\n",
        "        h = self.conv2(h)\n",
        "\n",
        "        # Add the shortcut (residual connection)\n",
        "        return h + self.shortcut(x)\n",
        "\n",
        "# TO DO: Compare this to the Diffusion-LM paper. The implementation is a bit more complicated there\n",
        "class AttentionBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    An attention block that allows spatial positions to attend to each other.\n",
        "\n",
        "    :param channels: number of input channels\n",
        "    :param num_heads: number of attention heads\n",
        "\n",
        "    This block:\n",
        "    - Normalizes the input.\n",
        "    - Computes self-attention using queries, keys, and values.\n",
        "    - Projects the output back to the input space.\n",
        "    \"\"\"\n",
        "    # TO DO: Check number of attention heads we should be using. They do use 1 in the Diffusion-LM code\n",
        "    def __init__(self, channels, num_heads=1):\n",
        "        super(AttentionBlock, self).__init__()\n",
        "        self.channels = channels\n",
        "        self.num_heads = num_heads\n",
        "        # Normalization and linear layers for QKV computation and projection\n",
        "        self.norm = nn.GroupNorm(32, channels)\n",
        "        self.qkv = nn.Conv1d(channels, channels * 3, kernel_size=1)\n",
        "        self.proj_out = nn.Conv1d(channels, channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass for the Attention Block.\n",
        "\n",
        "        :param x: Input tensor.\n",
        "\n",
        "        :return: Output tensor after self-attention.\n",
        "        \"\"\"\n",
        "        b, c, l = x.shape\n",
        "        h = self.norm(x)\n",
        "        # Compute queries, keys, and values\n",
        "        qkv = self.qkv(h)\n",
        "        qkv = qkv.reshape(b, self.num_heads * 3, c // self.num_heads, l)\n",
        "        q, k, v = torch.chunk(qkv, 3, dim=1)\n",
        "        # Compute scaled dot-product attention\n",
        "        scale = 1 / math.sqrt(math.sqrt(c // self.num_heads))\n",
        "        weight = torch.einsum('bhdn,bhfn->bhdf', q * scale, k * scale)\n",
        "        weight = torch.softmax(weight, dim=-1)\n",
        "        # Apply attention weights to values and reshape\n",
        "        h = torch.einsum('bhdf,bhfn->bhdn', weight, v)\n",
        "        h = h.reshape(b, c, l)\n",
        "        # Project back to input space and add residual connection\n",
        "        h = self.proj_out(h)\n",
        "        return x + h\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "    \"\"\"\n",
        "    Downsampling block using strided convolution.\n",
        "\n",
        "    :param channels: Number of input channels.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super(Downsample, self).__init__()\n",
        "        # TO DO: Maybe change to exactly match Diffusion-LM. Maybe make convolution optional\n",
        "        self.conv = nn.Conv1d(channels, channels, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    \"\"\"\n",
        "    Upsampling block using transposed convolution.\n",
        "\n",
        "    :param channels: Number of input channels.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super(Upsample, self).__init__()\n",
        "        # TO DO: Maybe change to exactly match Diffusion-LM. Maybe make convolution optional\n",
        "        self.conv = nn.ConvTranspose1d(channels, channels, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "# TO DO: Implement the rounding trick from Diffusion-ML\n",
        "class UNet(nn.Module):\n",
        "    \"\"\"\n",
        "    A U-Net architecture with ResBlocks, AttentionBlocks, and Down/Upsampling.\n",
        "\n",
        "    :param in_channels: Number of input channels.\n",
        "    :param model_channels: Base number of channels for the model.\n",
        "    :param out_channels: Number of output channels.\n",
        "    :param num_res_blocks: Number of ResBlocks at each resolution.\n",
        "    :param time_emb_dim: Dimensionality of the timestep embeddings.\n",
        "    :param channel_mult: Multipliers for channels at each level.\n",
        "    :param attention_resolutions: Resolutions to apply attention blocks.\n",
        "    :param dropout: Dropout probability.\n",
        "\n",
        "    The UNet is structured into three main parts:\n",
        "    1. Downsampling Path: Captures multi-scale features from the input.\n",
        "    2. Middle Block: Processes the lowest-resolution features with attention.\n",
        "    3. Upsampling Path: Reconstructs the output using features from the downsampling path (skip connections).\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        model_channels,\n",
        "        out_channels,\n",
        "        num_res_blocks,\n",
        "        time_emb_dim,\n",
        "        channel_mult=(1, 2, 4),\n",
        "        attention_resolutions=[],\n",
        "        dropout=0.0,\n",
        "    ):\n",
        "        super(UNet, self).__init__()\n",
        "        self.model_channels = model_channels\n",
        "        self.time_emb_dim = time_emb_dim\n",
        "        # Timestep embedding: Encodes time information into a vector\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(model_channels, time_emb_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_emb_dim, time_emb_dim),\n",
        "        )\n",
        "        # Input convolution to map input channels to base model channels\n",
        "        self.input_blocks = nn.ModuleList()\n",
        "        self.input_blocks.append(\n",
        "            TimestepEmbedSequential(\n",
        "                nn.Conv1d(in_channels, model_channels, kernel_size=3, padding=1)\n",
        "            )\n",
        "        )\n",
        "        input_block_chans = [model_channels]\n",
        "        ch = model_channels\n",
        "        ds = 1  # Downsampling factor\n",
        "\n",
        "        # Downsampling path\n",
        "        for level, mult in enumerate(channel_mult):\n",
        "            for _ in range(num_res_blocks):\n",
        "                # Add ResBlock(s) for this resolution\n",
        "                layers = [\n",
        "                    ResBlock(\n",
        "                        ch,\n",
        "                        mult * model_channels,\n",
        "                        time_emb_dim,\n",
        "                        dropout=dropout,\n",
        "                    )\n",
        "                ]\n",
        "                ch = mult * model_channels\n",
        "                # Add AttentionBlock if this resolution supports attention\n",
        "                if ds in attention_resolutions:\n",
        "                    layers.append(AttentionBlock(ch))\n",
        "                self.input_blocks.append(TimestepEmbedSequential(*layers))\n",
        "                input_block_chans.append(ch)\n",
        "            # Add Downsample layer at the end of this resolution level\n",
        "            if level != len(channel_mult) - 1:\n",
        "                self.input_blocks.append(\n",
        "                    TimestepEmbedSequential(Downsample(ch))\n",
        "                )\n",
        "                input_block_chans.append(ch)\n",
        "                ds *= 2 # Update downsampling factor\n",
        "\n",
        "        # Middle Block: Combines ResBlock and AttentionBlock at the lowest resolution\n",
        "        self.middle_block = TimestepEmbedSequential(\n",
        "            ResBlock(ch, ch, time_emb_dim, dropout=dropout),\n",
        "            AttentionBlock(ch),\n",
        "            ResBlock(ch, ch, time_emb_dim, dropout=dropout),\n",
        "        )\n",
        "\n",
        "        # Upsampling path\n",
        "        self.output_blocks = nn.ModuleList()\n",
        "        for level, mult in list(enumerate(channel_mult))[::-1]: # Reverse the levels\n",
        "            for _ in range(num_res_blocks + 1):\n",
        "                # Fetch the skip connection input channels from the down path\n",
        "                ich = input_block_chans.pop()\n",
        "                # Add ResBlock(s) that combine skip connection and current feature map\n",
        "                layers = [\n",
        "                    ResBlock(\n",
        "                        ch + ich, # Concatenate channels from skip connection\n",
        "                        model_channels * mult,\n",
        "                        time_emb_dim,\n",
        "                        dropout=dropout,\n",
        "                    )\n",
        "                ]\n",
        "                ch = model_channels * mult\n",
        "                # Add AttentionBlock if this resolution supports attention\n",
        "                if ds in attention_resolutions:\n",
        "                    layers.append(AttentionBlock(ch))\n",
        "                # Add Upsample layer at the end of this resolution level\n",
        "                if level and _ == num_res_blocks:\n",
        "                    layers.append(Upsample(ch))\n",
        "                    ds //= 2 # Update upsampling factor\n",
        "                self.output_blocks.append(TimestepEmbedSequential(*layers))\n",
        "\n",
        "        # Final output layers: Normalize, activate, and map to the desired output channels\n",
        "        self.out = nn.Sequential(\n",
        "            nn.GroupNorm(32, ch),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv1d(ch, out_channels, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(model_channels)\n",
        "\n",
        "        # Adjust initialization for convolutional and linear layers\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        \"\"\"\n",
        "        Forward pass through the UNet.\n",
        "\n",
        "        :param x: Input tensor.\n",
        "        :param t: Timestep tensor.\n",
        "        :return: Output tensor after processing.\n",
        "        \"\"\"\n",
        "        # Compute the timestep embeddings\n",
        "        t_emb = timestep_embedding(t, self.model_channels)\n",
        "        t_emb = self.time_embed(t_emb)\n",
        "\n",
        "        hs = []  # List to store intermediate feature maps for skip connections\n",
        "        h = x\n",
        "        # Downsampling Path\n",
        "        for module in self.input_blocks:\n",
        "            h = module(h, t_emb)\n",
        "            hs.append(h) # Save the feature map for later use in the upsampling path\n",
        "\n",
        "        # Middle Block\n",
        "        h = self.middle_block(h, t_emb)\n",
        "\n",
        "        # Upsampling Path\n",
        "        for module in self.output_blocks:\n",
        "            # Fetch the corresponding skip connection feature map\n",
        "            ich = hs.pop()\n",
        "            h = torch.cat([h, ich], dim=1) # Concatenate along the channel dimension\n",
        "            h = module(h, t_emb)\n",
        "        # Final Output Layer\n",
        "        return self.out(h)"
      ],
      "metadata": {
        "id": "aEjElFGlX9Tk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Gaussian Diffusion\n",
        "\n",
        "Functions to perform the diffusion process. This is the part that needs to be adapted according to the paper."
      ],
      "metadata": {
        "id": "ZZuKbEJ7viuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO: In the paper they don't presicd the noise they predict the embedding at each time step\n",
        "# Need to change this to allow this option here so we can apply rounding tricks from Diffusion-LM\n",
        "\n",
        "class GaussianDiffusion:\n",
        "    '''\n",
        "    Utilities for Gaussian diffusion process.\n",
        "\n",
        "    :param betas: A list of diffusion coefficients representing the noise schedule.\n",
        "    '''\n",
        "    def __init__(self, betas):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        # Convert betas to a tensor and move it to device\n",
        "        self.betas = torch.tensor(betas, dtype=torch.float32, device=self.device)\n",
        "        # Number of diffusion steps (timesteps)\n",
        "        self.num_timesteps = len(betas)\n",
        "\n",
        "        # Compute alpha values (1 - beta) and their cumulative products\n",
        "        alphas = 1.0 - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(alphas, dim=0).clamp(min=1e-10)\n",
        "        self.alphas_cumprod_prev = torch.cat([torch.tensor([1.0], device=self.device), self.alphas_cumprod[:-1]])\n",
        "\n",
        "        # Precompute square roots and related terms for efficiency\n",
        "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
        "        self.sqrt_alphas_cumprod_prev = torch.sqrt(self.alphas_cumprod_prev)\n",
        "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod).clamp(min=1e-10)\n",
        "        self.one_minus_alphas_cumprod_prev = (1.0 - self.alphas_cumprod_prev).clamp(min=1e-10)\n",
        "\n",
        "        # Precompute log-variance terms for later use\n",
        "        self.logvar = torch.log(torch.cat([self.betas[1:2], self.betas[1:]]))\n",
        "\n",
        "    def q_sample(self, x_start, t, noise=None):\n",
        "        \"\"\"\n",
        "        Sample from the forward process q(x_t | x_0).\n",
        "\n",
        "        :param x_start: The original data (x0).\n",
        "        :param t: The current timestep.\n",
        "        :param noise: Optional noise; if not provided, it is generated.\n",
        "        :return: The noisy data x_t\n",
        "        \"\"\"\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x_start) # Generate Gaussian noise if not provided\n",
        "\n",
        "        # Extract time-dependent coefficients for the current timestep\n",
        "        sqrt_alphas_cumprod_t = self._extract(self.sqrt_alphas_cumprod, t, x_start.shape)\n",
        "        sqrt_one_minus_alphas_cumprod_t = self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape)\n",
        "        # Apply the forward noise equation\n",
        "        return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise\n",
        "\n",
        "    def p_mean_variance(self, model, x_t, t):\n",
        "        \"\"\"\n",
        "        Compute the posterior mean and variance for the reverse process p(x_{t-1} | x_t).\n",
        "\n",
        "        :param model: The noise prediction model.\n",
        "        :param x_t: The noisy data at timestep \\( t \\).\n",
        "        :param t: The current timestep.\n",
        "\n",
        "        :return: A tuple containing the posterior mean and variance.\n",
        "        \"\"\"\n",
        "\n",
        "        # Add more comprehensive checks before computation\n",
        "        if torch.any(torch.isnan(x_t)):\n",
        "            raise ValueError(f\"NaN detected in x_t before prediction at t={t.item()}\")\n",
        "\n",
        "        # Clip input values to prevent extreme values\n",
        "        x_t = torch.clamp(x_t, min=-10, max=10)\n",
        "\n",
        "        # Predict the noise using the model\n",
        "        pred_noise = model(x_t, t)\n",
        "\n",
        "        # More robust NaN checks\n",
        "        if torch.any(torch.isnan(pred_noise)):\n",
        "            print(\"Checking model inputs and outputs...\")\n",
        "            print(f\"Input x_t stats: mean={x_t.mean()}, std={x_t.std()}, min={x_t.min()}, max={x_t.max()}\")\n",
        "            print(f\"Predicted noise stats: mean={pred_noise.mean()}, std={pred_noise.std()}\")\n",
        "            raise ValueError(f\"NaN detected in pred_noise at t={t.item()}\")\n",
        "\n",
        "        # Predict x0 (the original signal) from the noisy input and predicted noise\n",
        "        x0_pred = self._predict_xstart_from_eps(x_t, t, pred_noise)\n",
        "\n",
        "        # Check for NaNs in the predicted x0\n",
        "        if torch.isnan(x0_pred).any():\n",
        "            raise ValueError(f\"NaN detected in x0_pred at t={t.item()}\")\n",
        "\n",
        "        # Extract the necessary coefficients for model_mean computation\n",
        "        sqrt_alphas_cumprod_prev = self._extract(self.sqrt_alphas_cumprod_prev, t, x_t.shape)\n",
        "        one_minus_alphas_cumprod_prev = self._extract(self.one_minus_alphas_cumprod_prev, t, x_t.shape)\n",
        "\n",
        "        # Compute the posterior mean using the extracted coefficients\n",
        "        model_mean = sqrt_alphas_cumprod_prev * x0_pred + one_minus_alphas_cumprod_prev * x_t\n",
        "\n",
        "        # Check for NaNs in the model_mean\n",
        "        if torch.isnan(model_mean).any():\n",
        "            raise ValueError(f\"NaN detected in model_mean at t={t.item()}\")\n",
        "\n",
        "        # Extract the model variance\n",
        "        model_variance = self._extract(self.betas, t, x_t.shape)\n",
        "\n",
        "        # Additional Debugging: Check for NaNs or negative values in model_variance\n",
        "        if torch.isnan(model_variance).any():\n",
        "            raise ValueError(f\"NaN detected in model_variance at t={t.item()}\")\n",
        "        if torch.any(model_variance < 0):\n",
        "            raise ValueError(f\"Negative values detected in model_variance at t={t.item()}\")\n",
        "\n",
        "        return model_mean, model_variance, pred_noise\n",
        "\n",
        "\n",
        "\n",
        "    def _predict_xstart_from_eps(self, x_t, t, eps):\n",
        "        \"\"\"\n",
        "        Predict x_0 (original data) from x_t and the predicted noise.\n",
        "\n",
        "        :param model: The noise prediction model.\n",
        "        :param x_t: The noisy data at timestep t.\n",
        "        :param t: The current timestep.\n",
        "        :param eps: The predicted noise.\n",
        "\n",
        "        :return: The reconstructed x_0.\n",
        "        \"\"\"\n",
        "        sqrt_alphas_cumprod_t = self._extract(self.sqrt_alphas_cumprod, t, x_t.shape)\n",
        "        sqrt_one_minus_alphas_cumprod_t = self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_t.shape)\n",
        "\n",
        "        if torch.any(sqrt_alphas_cumprod_t == 0):\n",
        "            print(f\"Zero detected in sqrt_alphas_cumprod_t at t={t.item()}\")\n",
        "            sqrt_alphas_cumprod_t = sqrt_alphas_cumprod_t + 1e-10\n",
        "\n",
        "        # Reverse the forward noise process to reconstruct x_0\n",
        "        x0_pred = (x_t - sqrt_one_minus_alphas_cumprod_t * eps) / sqrt_alphas_cumprod_t\n",
        "        return x0_pred\n",
        "\n",
        "\n",
        "    def p_sample(self, model, x_t, t):\n",
        "        \"\"\"\n",
        "        Sample from the reverse process p(x_{t-1} | x_t).\n",
        "\n",
        "        :param model: The noise prediction model.\n",
        "        :param x_t: The noisy data at timestep t.\n",
        "        :param t: The current timestep.\n",
        "        :return: The denoised data x_{t-1}.\n",
        "        \"\"\"\n",
        "\n",
        "        # Compute mean and variance for the reverse process\n",
        "        model_mean, model_variance, _ = self.p_mean_variance(model, x_t, t)\n",
        "\n",
        "        # Check for NaNs in model_mean and model_variance\n",
        "        if torch.isnan(model_mean).any():\n",
        "            print(f\"NaN detected in model_mean at t={t.item()}\")\n",
        "        if torch.isnan(model_variance).any():\n",
        "            print(f\"NaN detected in model_variance at t={t.item()}\")\n",
        "\n",
        "        # Generate noise for sampling (no noise at t=0)\n",
        "        noise = torch.randn_like(x_t) if t[0] > 0 else torch.zeros_like(x_t)\n",
        "\n",
        "        # Check for NaNs in model_variance before sqrt\n",
        "        if torch.isnan(model_variance).any() or torch.any(model_variance < 0):\n",
        "            print(f\"Invalid model_variance at t={t.item()}\")\n",
        "            return x_t\n",
        "\n",
        "        # Sample from the Gaussian distribution\n",
        "        return model_mean + torch.sqrt(model_variance) * noise\n",
        "\n",
        "\n",
        "    def _extract(self, a, t, x_shape):\n",
        "        \"\"\"\n",
        "        Extract the coefficients for a specific timestep t.\n",
        "\n",
        "        :param a: The precomputed values (e.g., alphas, betas).\n",
        "        :param t: The current timestep.\n",
        "        :param x_shape: The shape of the input data.\n",
        "\n",
        "        :return: Extracted coefficients reshaped to match the input data.\n",
        "        \"\"\"\n",
        "        out = a.gather(-1, t).float()\n",
        "        while len(out.shape) < len(x_shape):\n",
        "            out = out.unsqueeze(-1)\n",
        "        return out\n",
        "\n",
        "\n",
        "    def p_sample_loop(self, model, shape, device):\n",
        "        \"\"\"\n",
        "        Generate a sample by iteratively applying the reverse process.\n",
        "\n",
        "        :param model: The noise prediction model.\n",
        "        :param shape: The shape of the output sample.\n",
        "        :param device: The device to run the computation.\n",
        "\n",
        "        :return: The generated sample.\n",
        "        \"\"\"\n",
        "        # Initialize x_T as Gaussian noise\n",
        "        # TO DO: Replace this later\n",
        "        x_t = torch.randn(shape, device=device)\n",
        "        # Iteratively sample from p(x_{t-1} | x_t)\n",
        "        for t_step in reversed(range(self.num_timesteps)):\n",
        "            t = torch.tensor([t_step] * shape[0], device=device)\n",
        "            x_t = self.p_sample(model, x_t, t)\n",
        "        return x_t"
      ],
      "metadata": {
        "id": "iHSyirHNvb7a"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Generate Toy Data and Initialize Model, Optimizer, etc.\n",
        "\n",
        "This code generates a toy dataset that will be repalced by the actual data that we're going to use. I wanted to make sure things were working!"
      ],
      "metadata": {
        "id": "HCiBa4YJw3-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "prK-v0gFGhRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "14830804-3f3a-40f4-c350-d8c323fccd2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (time_embed): Sequential(\n",
              "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
              "    (1): SiLU()\n",
              "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (input_blocks): ModuleList(\n",
              "    (0): TimestepEmbedSequential(\n",
              "      (0): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "    )\n",
              "    (1-2): 2 x TimestepEmbedSequential(\n",
              "      (0): ResBlock(\n",
              "        (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "        (activation1): SiLU()\n",
              "        (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (time_mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=64, bias=True)\n",
              "        )\n",
              "        (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "        (activation2): SiLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (shortcut): Identity()\n",
              "      )\n",
              "    )\n",
              "    (3): TimestepEmbedSequential(\n",
              "      (0): Downsample(\n",
              "        (conv): Conv1d(64, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
              "      )\n",
              "    )\n",
              "    (4): TimestepEmbedSequential(\n",
              "      (0): ResBlock(\n",
              "        (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "        (activation1): SiLU()\n",
              "        (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (time_mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "        (activation2): SiLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (shortcut): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "    )\n",
              "    (5): TimestepEmbedSequential(\n",
              "      (0): ResBlock(\n",
              "        (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "        (activation1): SiLU()\n",
              "        (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (time_mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "        (activation2): SiLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (shortcut): Identity()\n",
              "      )\n",
              "    )\n",
              "    (6): TimestepEmbedSequential(\n",
              "      (0): Downsample(\n",
              "        (conv): Conv1d(128, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
              "      )\n",
              "    )\n",
              "    (7): TimestepEmbedSequential(\n",
              "      (0): ResBlock(\n",
              "        (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "        (activation1): SiLU()\n",
              "        (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (time_mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "        (activation2): SiLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (shortcut): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (1): AttentionBlock(\n",
              "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "        (qkv): Conv1d(256, 768, kernel_size=(1,), stride=(1,))\n",
              "        (proj_out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "    )\n",
              "    (8): TimestepEmbedSequential(\n",
              "      (0): ResBlock(\n",
              "        (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "        (activation1): SiLU()\n",
              "        (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (time_mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "        (activation2): SiLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (shortcut): Identity()\n",
              "      )\n",
              "      (1): AttentionBlock(\n",
              "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "        (qkv): Conv1d(256, 768, kernel_size=(1,), stride=(1,))\n",
              "        (proj_out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (middle_block): TimestepEmbedSequential(\n",
              "    (0): ResBlock(\n",
              "      (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "      (activation1): SiLU()\n",
              "      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (time_mlp): Sequential(\n",
              "        (0): SiLU()\n",
              "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "      )\n",
              "      (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "      (activation2): SiLU()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (shortcut): Identity()\n",
              "    )\n",
              "    (1): AttentionBlock(\n",
              "      (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "      (qkv): Conv1d(256, 768, kernel_size=(1,), stride=(1,))\n",
              "      (proj_out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "    (2): ResBlock(\n",
              "      (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "      (activation1): SiLU()\n",
              "      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (time_mlp): Sequential(\n",
              "        (0): SiLU()\n",
              "        (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "      )\n",
              "      (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "      (activation2): SiLU()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (shortcut): Identity()\n",
              "    )\n",
              "  )\n",
              "  (output_blocks): ModuleList(\n",
              "    (0-1): 2 x TimestepEmbedSequential(\n",
              "      (0): ResBlock(\n",
              "        (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
              "        (activation1): SiLU()\n",
              "        (conv1): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (time_mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "        (activation2): SiLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (shortcut): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (1): AttentionBlock(\n",
              "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "        (qkv): Conv1d(256, 768, kernel_size=(1,), stride=(1,))\n",
              "        (proj_out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "    )\n",
              "    (2): TimestepEmbedSequential(\n",
              "      (0): ResBlock(\n",
              "        (norm1): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
              "        (activation1): SiLU()\n",
              "        (conv1): Conv1d(384, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (time_mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "        (activation2): SiLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (shortcut): Conv1d(384, 256, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (1): AttentionBlock(\n",
              "        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "        (qkv): Conv1d(256, 768, kernel_size=(1,), stride=(1,))\n",
              "        (proj_out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (2): Upsample(\n",
              "        (conv): ConvTranspose1d(256, 256, kernel_size=(4,), stride=(2,), padding=(1,))\n",
              "      )\n",
              "    )\n",
              "    (3): TimestepEmbedSequential(\n",
              "      (0): ResBlock(\n",
              "        (norm1): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
              "        (activation1): SiLU()\n",
              "        (conv1): Conv1d(384, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (time_mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "        (activation2): SiLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (shortcut): Conv1d(384, 128, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "    )\n",
              "    (4): TimestepEmbedSequential(\n",
              "      (0): ResBlock(\n",
              "        (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "        (activation1): SiLU()\n",
              "        (conv1): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (time_mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "        (activation2): SiLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (shortcut): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "    )\n",
              "    (5): TimestepEmbedSequential(\n",
              "      (0): ResBlock(\n",
              "        (norm1): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
              "        (activation1): SiLU()\n",
              "        (conv1): Conv1d(192, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (time_mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "        (activation2): SiLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (shortcut): Conv1d(192, 128, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "      (1): Upsample(\n",
              "        (conv): ConvTranspose1d(128, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
              "      )\n",
              "    )\n",
              "    (6): TimestepEmbedSequential(\n",
              "      (0): ResBlock(\n",
              "        (norm1): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
              "        (activation1): SiLU()\n",
              "        (conv1): Conv1d(192, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (time_mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=64, bias=True)\n",
              "        )\n",
              "        (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "        (activation2): SiLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (shortcut): Conv1d(192, 64, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "    )\n",
              "    (7-8): 2 x TimestepEmbedSequential(\n",
              "      (0): ResBlock(\n",
              "        (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
              "        (activation1): SiLU()\n",
              "        (conv1): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (time_mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=64, bias=True)\n",
              "        )\n",
              "        (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "        (activation2): SiLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "        (shortcut): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (out): Sequential(\n",
              "    (0): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
              "    (1): SiLU()\n",
              "    (2): Conv1d(64, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "  )\n",
              "  (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Parameters\n",
        "num_samples = 1000       # Total number of samples in the dataset\n",
        "sequence_length = 128    # Length of each time series (sine wave)\n",
        "batch_size = 32\n",
        "\n",
        "# Generate data\n",
        "x = np.linspace(-np.pi, np.pi, sequence_length)\n",
        "\n",
        "# Generate multiple sine waves with random parameters\n",
        "y_list = []\n",
        "for _ in range(num_samples):\n",
        "    amplitude = np.random.uniform(0.5, 1.5)\n",
        "    frequency = np.random.uniform(0.8, 1.2)\n",
        "    phase = np.random.uniform(0, 2 * np.pi)\n",
        "    y = amplitude * np.sin(frequency * x + phase)\n",
        "    y_list.append(y)\n",
        "\n",
        "y_array = np.array(y_list)  # Shape: [num_samples, sequence_length]\n",
        "\n",
        "# Prepare dataset\n",
        "y_tensor = torch.tensor(y_array).float()  # Shape: [num_samples, sequence_length]\n",
        "\n",
        "# Reshape for Conv1D (batch_size, channels, sequence_length)\n",
        "y_tensor = y_tensor.unsqueeze(1)  # Shape: [num_samples, 1, sequence_length]\n",
        "\n",
        "dataset = TensorDataset(y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Hyperparameters\n",
        "betas = get_beta_schedule('linear', 1000)\n",
        "assert np.all(betas > 0), \"Betas must be positive.\"\n",
        "num_timesteps = len(betas)\n",
        "time_emb_dim = 256\n",
        "learning_rate = 1e-4\n",
        "epochs = 20\n",
        "\n",
        "# Initialize diffusion and model\n",
        "diffusion = GaussianDiffusion(betas)\n",
        "model = UNet(\n",
        "    in_channels=1,\n",
        "    model_channels=64,\n",
        "    out_channels=1,\n",
        "    num_res_blocks=2,\n",
        "    time_emb_dim=time_emb_dim,\n",
        "    channel_mult=(1, 2, 4),\n",
        "    attention_resolutions=[4],  # Add attention at specified resolutions\n",
        "    dropout=0.1,\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate,\n",
        "    weight_decay=1e-5,  # Add weight decay\n",
        "    eps=1e-8  # Add small epsilon to prevent division by zero\n",
        ")\n",
        "\n",
        "# Consider learning rate scheduling\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-5\n",
        ")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Set model to training mode\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Train the Model!"
      ],
      "metadata": {
        "id": "l_Xk9odew_mJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s: %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler(sys.stdout),\n",
        "        logging.FileHandler('training_log.txt')\n",
        "    ]\n",
        ")\n",
        "\n",
        "def train_diffusion_model(\n",
        "    model,\n",
        "    diffusion,\n",
        "    dataloader,\n",
        "    optimizer,\n",
        "    scheduler=None,\n",
        "    device=None,\n",
        "    max_epochs=20,\n",
        "    gradient_clip_norm=1.0,\n",
        "    early_stopping_patience=5\n",
        "):\n",
        "    \"\"\"\n",
        "    Training Loop for Diffusion Model.\n",
        "\n",
        "    :param model: Diffusion model.\n",
        "    :param diffusion: Diffusion process handler.\n",
        "    :param dataloader: Data loader.\n",
        "    :param optimizer: Optimizer.\n",
        "    :param scheduler: Learning rate scheduler.\n",
        "    :param device: Computing device.\n",
        "    :param max_epochs: Maximum number of training epochs.\n",
        "    :param gradient_clip_norm: Maximum norm for gradient clipping.\n",
        "    :param early_stopping_patience: Epochs to wait for improvement.\n",
        "\n",
        "    :return: Training history with losses and other metrics.\n",
        "    \"\"\"\n",
        "    # Default device setup\n",
        "    if device is None:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Move model to device\n",
        "    model.to(device)\n",
        "\n",
        "    # Training history tracking\n",
        "    training_history = {\n",
        "        'train_loss': [],\n",
        "        'lr': []\n",
        "    }\n",
        "\n",
        "    # Early stopping variables\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Ensure model is in training mode\n",
        "    model.train()\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(max_epochs):\n",
        "        epoch_loss = 0.0\n",
        "        batch_count = 0\n",
        "\n",
        "        # Progress bar for the epoch\n",
        "        progress_bar = tqdm(\n",
        "            dataloader,\n",
        "            desc=f'Epoch {epoch+1}/{max_epochs}',\n",
        "            total=len(dataloader)\n",
        "        )\n",
        "\n",
        "        for batch in progress_bar:\n",
        "            try:\n",
        "                # Prepare batch\n",
        "                batch_y = batch[0].to(device)\n",
        "                batch_size = batch_y.size(0)\n",
        "\n",
        "                # Randomly select timesteps\n",
        "                t = torch.randint(\n",
        "                    0,\n",
        "                    diffusion.num_timesteps,\n",
        "                    (batch_size,),\n",
        "                    dtype=torch.long\n",
        "                ).to(device)\n",
        "\n",
        "                # Add noise to the data\n",
        "                noise = torch.randn_like(batch_y)\n",
        "                x_t = diffusion.q_sample(batch_y, t, noise)\n",
        "\n",
        "                # Safety checks on input tensors\n",
        "                if torch.isnan(x_t).any() or torch.isinf(x_t).any():\n",
        "                    logging.warning(f\"Detected NaN/Inf in noisy input at epoch {epoch}\")\n",
        "                    continue\n",
        "\n",
        "                # Zero gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Predict noise\n",
        "                with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n",
        "                    pred_noise = model(x_t, t)\n",
        "\n",
        "                    # Safety checks on predicted noise\n",
        "                    if torch.isnan(pred_noise).any() or torch.isinf(pred_noise).any():\n",
        "                        logging.warning(f\"Detected NaN/Inf in predicted noise at epoch {epoch}\")\n",
        "                        continue\n",
        "\n",
        "                    # Compute loss\n",
        "                    loss = F.mse_loss(pred_noise, noise)\n",
        "\n",
        "                # Backward pass with gradient scaling (for mixed precision)\n",
        "                loss.backward()\n",
        "\n",
        "                # Gradient clipping\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=gradient_clip_norm)\n",
        "\n",
        "                # Optimizer step\n",
        "                optimizer.step()\n",
        "\n",
        "                # Accumulate metrics\n",
        "                epoch_loss += loss.item()\n",
        "                batch_count += 1\n",
        "\n",
        "                # Update progress bar\n",
        "                progress_bar.set_postfix({'Loss': loss.item()})\n",
        "\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error in training batch: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Compute average epoch loss\n",
        "        avg_loss = epoch_loss / max(batch_count, 1)\n",
        "        training_history['train_loss'].append(avg_loss)\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        if scheduler:\n",
        "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                scheduler.step(avg_loss)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "            training_history['lr'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        # Logging\n",
        "        logging.info(f'Epoch {epoch+1}: Avg Loss = {avg_loss:.4f}')\n",
        "\n",
        "        # Early stopping\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "            # Optional: Save best model\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Stop if no improvement\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            logging.info(f'Early stopping triggered after {epoch+1} epochs')\n",
        "            break\n",
        "\n",
        "    return training_history\n",
        "\n",
        "# Run the training function to train!\n",
        "history = train_diffusion_model(\n",
        "     model=model,\n",
        "     diffusion=diffusion,\n",
        "     dataloader=dataloader,\n",
        "     optimizer=optimizer,\n",
        "     scheduler=scheduler  # Optional\n",
        " )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4YVLLNBIX25",
        "outputId": "e4155ee5-177c-453f-fb60-fe2af9f650ca"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20:   0%|          | 0/32 [00:00<?, ?it/s]<ipython-input-30-51918ef59034>:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=device.type == 'cuda'):\n",
            "Epoch 1/20: 100%|██████████| 32/32 [00:01<00:00, 16.04it/s, Loss=0.166]\n",
            "Epoch 2/20: 100%|██████████| 32/32 [00:01<00:00, 16.25it/s, Loss=0.0769]\n",
            "Epoch 3/20: 100%|██████████| 32/32 [00:02<00:00, 15.95it/s, Loss=0.0504]\n",
            "Epoch 4/20: 100%|██████████| 32/32 [00:01<00:00, 16.07it/s, Loss=0.0602]\n",
            "Epoch 5/20: 100%|██████████| 32/32 [00:01<00:00, 16.32it/s, Loss=0.0574]\n",
            "Epoch 6/20: 100%|██████████| 32/32 [00:02<00:00, 16.00it/s, Loss=0.119]\n",
            "Epoch 7/20: 100%|██████████| 32/32 [00:01<00:00, 16.04it/s, Loss=0.0508]\n",
            "Epoch 8/20: 100%|██████████| 32/32 [00:01<00:00, 16.26it/s, Loss=0.0394]\n",
            "Epoch 9/20: 100%|██████████| 32/32 [00:02<00:00, 15.61it/s, Loss=0.0389]\n",
            "Epoch 10/20: 100%|██████████| 32/32 [00:02<00:00, 15.47it/s, Loss=0.0346]\n",
            "Epoch 11/20: 100%|██████████| 32/32 [00:02<00:00, 15.85it/s, Loss=0.0279]\n",
            "Epoch 12/20: 100%|██████████| 32/32 [00:02<00:00, 15.28it/s, Loss=0.0342]\n",
            "Epoch 13/20: 100%|██████████| 32/32 [00:01<00:00, 16.06it/s, Loss=0.0294]\n",
            "Epoch 14/20: 100%|██████████| 32/32 [00:02<00:00, 15.85it/s, Loss=0.0359]\n",
            "Epoch 15/20: 100%|██████████| 32/32 [00:02<00:00, 15.79it/s, Loss=0.0295]\n",
            "Epoch 16/20: 100%|██████████| 32/32 [00:02<00:00, 15.87it/s, Loss=0.0303]\n",
            "Epoch 17/20: 100%|██████████| 32/32 [00:02<00:00, 15.97it/s, Loss=0.0332]\n",
            "Epoch 18/20: 100%|██████████| 32/32 [00:02<00:00, 15.67it/s, Loss=0.0201]\n",
            "Epoch 19/20: 100%|██████████| 32/32 [00:02<00:00, 15.99it/s, Loss=0.0395]\n",
            "Epoch 20/20: 100%|██████████| 32/32 [00:02<00:00, 15.39it/s, Loss=0.0363]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Generate a Sine Wave from Noise\n",
        "\n",
        "The noise of course be replaced later with an embedding of a cloud of points!"
      ],
      "metadata": {
        "id": "1Jj29oj3xc4j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-ujw8gbsIZvi"
      },
      "outputs": [],
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # TO DO: replace random noise with point embedding\n",
        "    # Start from pure noise\n",
        "    shape = (1, 1, sequence_length)  # (batch_size, channels, sequence_length)\n",
        "    x_t = torch.randn(shape).to(device)\n",
        "    for t_step in reversed(range(num_timesteps)):\n",
        "        t = torch.tensor([t_step], dtype=torch.long).to(device)\n",
        "        x_t = diffusion.p_sample(model, x_t, t)\n",
        "        if torch.isnan(x_t).any():\n",
        "            print(t)\n",
        "            break\n",
        "    generated_signal = x_t.squeeze().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "hAwUKVYTIcRC",
        "outputId": "bb5ce1d7-e14a-49e3-d341-21872fe7976b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAHHCAYAAABHp6kXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACy3UlEQVR4nOydd5xcZdXHf3f6zPbd7KZuekgISYAkBCQgAQKhCEQFXxExAV8EDF1eISqgIgQUFY0YQTSgggJKkyahC6GmQYD0Xjfbd6eX+/5x53nuc9uU3dmdsuf7+ewnO/2Zyc5zz/2d3zlHkmVZBkEQBEEQRJFjy/cCCIIgCIIgcgEFNQRBEARBlAQU1BAEQRAEURJQUEMQBEEQRElAQQ1BEARBECUBBTUEQRAEQZQEFNQQBEEQBFESUFBDEARBEERJQEENQRAEQRAlAQU1BEEMaEaPHo2FCxfm7Pl+/OMfQ5KknD1fb5kzZw7mzJmT72UQRL9AQQ1BFCnbt2/HVVddhcMOOww+nw8+nw+TJ0/GokWL8PHHH+d7eTnlhRdewI9//OO8rqG7uxu33XYbpkyZgrKyMtTV1eGoo47Ctddei3379uV1bQRBKEg0+4kgio/nnnsO//M//wOHw4GLLroIRx55JGw2GzZs2IAnn3wSO3fuxPbt2zFq1Kh8LzUnXHXVVbjvvvvQF9vV6NGjMWfOHDz00EOW94lGozj22GOxYcMGLFiwAEcddRS6u7vx6aef4t///jeeeOIJrobEYjHEYjF4PJ6cr7UnsHW98cYbeV0HQfQHjnwvgCCI7Ni6dSu+/vWvY9SoUXj11VcxdOhQze133303fv/738NmK1wh1u/3o6ysLN/LyJinn34aa9aswSOPPIJvfOMbmttCoRAikQi/7HA44HDQ1koQ+aBwdz2CIEz5+c9/Dr/fj+XLlxsCGkA5qF5zzTVobGzUXL9hwwacf/75qK2thcfjwcyZM/Hss89q7vPQQw9BkiS88847uOGGG1BfX4+ysjJ8+ctfxqFDhwyv9eKLL+LEE09EWVkZKioqcPbZZ+PTTz/V3GfhwoUoLy/H1q1bcdZZZ6GiogIXXXQRAOC///0vLrjgAowcORJutxuNjY24/vrrEQwGNY+/7777AACSJPEfRiKRwL333osjjjgCHo8HgwcPxuWXX462tjbNOmRZxs9+9jOMGDECPp8PJ598smGtVmzduhUAMHv2bMNtHo8HlZWV/LKZpyYYDOKaa67BoEGDUFFRgXPPPRd79+6FJEmatBp77JYtW7Bw4UJUV1ejqqoKl1xyCQKBgOY5ly9fjlNOOQUNDQ1wu92YPHkyli1bltH7IYhShU4nCKLIeO655zB+/Hgce+yxGT/m008/xezZszF8+HDcfPPNKCsrw+OPP4758+fjX//6F7785S9r7n/11VejpqYGt912G3bs2IF7770XV111FR577DF+n7/+9a9YsGAB5s2bh7vvvhuBQADLli3DCSecgDVr1mD06NH8vrFYDPPmzcMJJ5yAe+65Bz6fDwDwxBNPIBAI4Morr0RdXR0++OADLF26FHv27METTzwBALj88suxb98+rFixAn/9618N7+3yyy/HQw89hEsuuQTXXHMNtm/fjt/97ndYs2YN3nnnHTidTgDArbfeip/97Gc466yzcNZZZ2H16tU4/fTTNSqLFSyN95e//AU/+tGPsjYCL1y4EI8//jguvvhiHHfccXjzzTdx9tlnW97/a1/7GsaMGYMlS5Zg9erVePDBB9HQ0IC7776b32fZsmU44ogjcO6558LhcODf//43vvvd7yKRSGDRokVZrY8gSgaZIIiioaOjQwYgz58/33BbW1ubfOjQIf4TCAT4baeeeqo8depUORQK8esSiYR8/PHHyxMmTODXLV++XAYgz507V04kEvz666+/Xrbb7XJ7e7ssy7Lc1dUlV1dXy5dddplmDQcOHJCrqqo01y9YsEAGIN98882GNYtrZCxZskSWJEneuXMnv27RokWy2Xb13//+VwYgP/LII5rrX3rpJc31TU1Nssvlks8++2zN+/rBD34gA5AXLFhgeG79OidOnCgDkEeNGiUvXLhQ/tOf/iQfPHjQcN/bbrtNs9ZVq1bJAOTrrrtOc7+FCxfKAOTbbrvN8NhLL71Uc98vf/nLcl1dnWFNeubNmyePHTtWc91JJ50kn3TSSSnfH0GUCpR+IogiorOzEwBQXl5uuG3OnDmor6/nPyxl09raitdeew1f+9rX0NXVhebmZjQ3N6OlpQXz5s3D5s2bsXfvXs1zfec739GoESeeeCLi8Th27twJAFixYgXa29tx4YUX8udrbm6G3W7Hsccei9dff92wviuvvNJwndfr5b/7/X40Nzfj+OOPhyzLWLNmTdrP44knnkBVVRVOO+00zTpmzJiB8vJyvo5XXnkFkUgEV199teZ9XXfddWlfg63z/fffx//93/8BUNJ03/72tzF06FBcffXVCIfDlo996aWXAADf/e53NddfffXVlo+54oorNJdPPPFEtLS08P9/tiZGR0cHmpubcdJJJ2Hbtm3o6OjI6H0RRKlB6SeCKCIqKioAKOXFeu6//350dXXh4MGD+OY3v8mv37JlC2RZxi233IJbbrnF9HmbmpowfPhwfnnkyJGa22tqagCA+1Q2b94MADjllFNMn0/0mACKz2fEiBGG++3atQu33nornn32WYMHJpMD8+bNm9HR0YGGhgbT25uamgCAB2MTJkzQ3F5fX8/fWzqqqqrw85//HD//+c+xc+dOvPrqq7jnnnvwu9/9DlVVVfjZz35m+ridO3fCZrNhzJgxmuvHjx9v+VqpPn/22b7zzju47bbb8O677xr8Nh0dHaiqqsrofRFEKUFBDUEUEVVVVRg6dCjWr19vuI15bHbs2KG5PpFIAABuvPFGzJs3z/R59QdYu91uej85WVLNnvOvf/0rhgwZYrifvvrH7XYbqrHi8ThOO+00tLa24qabbsKkSZNQVlaGvXv3YuHChfw1UpFIJNDQ0IBHHnnE9Pb6+vq0z9ETRo0ahUsvvRRf/vKXMXbsWDzyyCOWQU1PSPf5b926FaeeeiomTZqEX/3qV2hsbITL5cILL7yAX//61xl9dgRRilBQQxBFxtlnn40HH3wQH3zwAWbNmpX2/mPHjgUAOJ1OzJ07NydrGDduHACgoaGhx8/5ySefYNOmTXj44YfxrW99i1+/YsUKw32tjLnjxo3DK6+8gtmzZ2vSMXqY0Xfz5s388wCAQ4cOGRSibKipqcG4ceNMg0zxtROJBLZv365RirZs2dLj1/33v/+NcDiMZ599VqPqmKX9CGIgQZ4agigyvv/978Pn8+HSSy/FwYMHDbfLugZ1DQ0NmDNnDu6//37s37/fcH+zUu10zJs3D5WVlbjzzjsRjUZ79JxMjRDXK8syfvOb3xjuy3ratLe3a67/2te+hng8jttvv93wmFgsxu8/d+5cOJ1OLF26VPN69957b9p1AsC6devQ3NxsuH7nzp347LPPMHHiRMvHMnXs97//veb6pUuXZvTaZph9dh0dHVi+fHmPn5MgSgFSagiiyJgwYQIeffRRXHjhhZg4cSLvKCzLMrZv345HH30UNptN42G57777cMIJJ2Dq1Km47LLLMHbsWBw8eBDvvvsu9uzZg3Xr1mW1hsrKSixbtgwXX3wxpk+fjq9//euor6/Hrl278Pzzz2P27Nn43e9+l/I5Jk2ahHHjxuHGG2/E3r17UVlZiX/961+mysmMGTMAANdccw3mzZsHu92Or3/96zjppJNw+eWXY8mSJVi7di1OP/10OJ1ObN68GU888QR+85vf4Pzzz0d9fT1uvPFGLFmyBF/60pdw1llnYc2aNXjxxRcxaNCgtO93xYoVuO2223DuuefiuOOOQ3l5ObZt24Y///nPCIfDKUc4zJgxA1/96ldx7733oqWlhZd0b9q0CYC1CpWK008/HS6XC+eccw4uv/xydHd3449//CMaGhpMA1eCGDDkq+yKIIjesWXLFvnKK6+Ux48fL3s8Htnr9cqTJk2Sr7jiCnnt2rWG+2/dulX+1re+JQ8ZMkR2Op3y8OHD5S996UvyP//5T34fVtL94Ycfah77+uuvywDk119/3XD9vHnz5KqqKtnj8cjjxo2TFy5cKH/00Uf8PgsWLJDLyspM38Nnn30mz507Vy4vL5cHDRokX3bZZfK6detkAPLy5cv5/WKxmHz11VfL9fX1siRJhvLuBx54QJ4xY4bs9XrliooKeerUqfL3v/99ed++ffw+8Xhc/slPfiIPHTpU9nq98pw5c+T169fLo0aNSlvSvW3bNvnWW2+VjzvuOLmhoUF2OBxyfX29fPbZZ8uvvfaa5r76km5ZlmW/3y8vWrRIrq2tlcvLy+X58+fLGzdulAHId911l+Gxhw4d0jye/b9s376dX/fss8/K06ZNkz0ejzx69Gj57rvvlv/85z8b7kcl3cRAgmY/EQRB5IG1a9fi6KOPxt/+9jfeYZkgiN5BnhqCIIg+Rhz7wLj33nths9nwxS9+MQ8rIojShDw1BEEQfczPf/5zrFq1CieffDIcDgdefPFFvPjii/jOd75jmNFFEETPofQTQRBEH7NixQr85Cc/wWeffYbu7m6MHDkSF198MX74wx/SRG+CyCEU1BAEQRAEURKQp4YgCIIgiJKAghqCIAiCIEqCAZXMTSQS2LdvHyoqKnrU8IogCIIgiP5HlmV0dXVh2LBhhjlyIgMqqNm3bx9VGhAEQRBEkbJ7925Nt3Q9AyqoqaioAKB8KJWVlXleDUEQBEEQmdDZ2YnGxkZ+HLdiQAU1LOVUWVlJQQ1BEARBFBnprCNkFCYIgiAIoiSgoIYgCIIgiJKAghqCIAiCIEoCCmoIgiAIgigJiiaoicfjuOWWWzBmzBh4vV6MGzcOt99+O2jKA0EQBEEQQBFVP919991YtmwZHn74YRxxxBH46KOPcMkll6CqqgrXXHNNvpdHEARBEESeKZqgZuXKlTjvvPNw9tlnAwBGjx6Nv//97/jggw/yvDKCIAiCIAqBokk/HX/88Xj11VexadMmAMC6devw9ttv48wzz7R8TDgcRmdnp+aHIAiCIIjSpGiUmptvvhmdnZ2YNGkS7HY74vE47rjjDlx00UWWj1myZAl+8pOf9OMqCYIgCILIF0Wj1Dz++ON45JFH8Oijj2L16tV4+OGHcc899+Dhhx+2fMzixYvR0dHBf3bv3t2PKyYIgiAIoj+R5CIpH2psbMTNN9+MRYsW8et+9rOf4W9/+xs2bNiQ0XN0dnaiqqoKHR0dNCaBIAiCIIqETI/fRaPUBAIBw7hxu92ORCKRpxURBEEQBFFIFI2n5pxzzsEdd9yBkSNH4ogjjsCaNWvwq1/9Cpdeemm+lzbgkWUZCRmw21IPGiMIgiCIvqRo0k9dXV245ZZb8NRTT6GpqQnDhg3DhRdeiFtvvRUulyuj56D0U9+w+MmP8dy6/Xjh2hPRWOvL93IIgiCIEiPT43fRBDW5gIKa3JNIyJj2k5fRHY7h9vOOwMVfGJ3vJREEQRAlRsl5aojCZEeLH93hGABg7e6OPK+GIAiCGMhQUEP0ik/2qoHMuj3tKe8bT8j41YpNeGbt3j5eFUEQBDEQKRqjMFGYrBeCmq2HutEZiqLS4zS978ufHsBvX92M2jIXzjtqeH8tkSAIghggkFJTYiQSMn758ka88tnBfnk9UamRZWD9HusU1EMrdwAA2gMRmq5OEARB5BwKakqM9fs6sPS1Lbjjhc8Nt8myjBseW4t7/rMxJ6+VSMj4dK8yT2tcfRkAYK1FCurz/Z14f3ur8jgZ8EfiOVkDQRAEQTAoqCkxWv0RAEBXKGq4bW97EE+u2Yvfvb4FgUgs6+eOJ7Tqys7WALrCMbgcNpw/oxEAsG53u+lj//LuDs3l7lD2r08QBEEQqaCgpsRglUihqLHTclBQR7Yd8mf1vFf8dRW++PPX0dId5tex1NPhQysxY1QNAGCdSQVUeyCCp9ZozcFmQRdBEARB9AYKakqMrhALaozpnaBw3Zam7oyfU5ZlvL6xCXvbg5rghJmEpw6vxJThlbBJwIHOEA50hDSPf/yj3QhFEzh8aCUaa70AgE5SagiCsCAUjaOpK5T+jgShg4KaEoOldWIJGdG4Vq0R1ZvNTV0ZP2cgEkc4pjz2aaEc+5M9LKipgs/lwGGDKwBoS7vjCRl/eXcnAGDh8aNQ4VYqo0ipIQjCim8//CFm3/UamjopsCGyg4KaEkMMFvRqTU+VmpbuCP99/d5ObD7YBVmWsX6fEtRMGV4FADiqsRqA1lfz2oYm7GkLotrnxHlHDUe5R+kiwNJkBEEQejYe6EY0LmNnayDfSyGKDApqSgwxraP31YhBzuZsghp/WHP5yTV7sbMlgK6QYhJmCs2RLKhJKjWRWAL3vrIJAPA/xzTC47SjMhnUdFH6iSAIC8LJvcosjU4QqaCgpsQQFRD9hiBe3tkSQCRmNBObwZQaNoT7mTV7eeBy+JAKOO3Kn9GRI6oBAB/v7kAiIeM3r27Cp/s6Ue1z4tsnjAEAVHgo/UQQRGpCMRbUZLZHEQSDgpoSI1X6SbwcT8jY0ZJZBRQrEz9ubB0qPA7s6wjhz+/sAKCmngDgsMHl8Dht6ArH8MSq3Vj2xlYAwJIvT0VDhQcAUMHST6TUEARhQiyeQDSutI8Imig1v39jC078+WuGggSCACioKTm0So21URgANh/MLAXVnEw/Dav24uypQwGovplpI9SgxmG3YWoyyPnBU+uRkIGvTB+OM5OPAYBytxLUUPUTQRBmhAQF2Sz99NL6A9jdGsT721v6c1lEkUBBTYkhelX0Zzn6y5mahVuT6ae6Mhe+fLR2ZpOo1ABqCiqekDG82osfn3uE5nY1/URBDUEUI+9va8HiJz/pdQr5rU2HTIfbioGMaWuKZL+tNn/EcBtBUFBTYnSHMvPUAJmXdbckN4+6cheOGV2L4dVKrxnRJMxgZmFJAn75tSMNwy0ruFGYPDUEUYz87vUt+PsHu/DahqYeP0c0nsDlf12F6x5bq2noCWibhKbqt9UWoD2EMEJBTYnRmYFSM3aQMqcpU6WGBTW1ZW7YbBJXa0STMGPu4YNx9tShuP28KThubJ3huSqopJsgihq2x/jDPa9M2nbIj2A0DlkGOoLa4CQcE4Mao1E4xIMaUmoII458L4DIns5QFN9/4mOce9QwnCX4VQCgO2xtFA4nN4gpw6uwrdmPbc1+xOIJOOypY1t2JlVX7gIAfPuEMdjdFsBXp48w3NfrsuO+i6ZbPlcFlXQTRFETSJ6QmJl4M2XDgU7+u+HkK5KwvE25XbmuldJPhAkU1BQhK7e04KVPD2B/Z0gT1ETjCc2ZTdiiT834hnK4HTaEYwnsbgtiTFK5sYJtHnVlSlBTU+bCb75+dI/WTiXdBFHcBCK97yGz6aCa+jakyWPW6SdZlnmg007pJ8IESj8VIVx+1Z2p6MukrdJPPpcd4+rLAaRPQcmyzPvU1JW7e77oJKTUEERx448klZqIMah59fODOOs3/8Xn+zsNt4lsPKAGNaIyA6Q2CkfjMhJKtTcpNYQpFNQUIaxpXrsup6wPFKyMwh6nHeMblKAmnVm4OxxDJDlDiik1vYGVdHeZeGqWvroZv311c69fgyCIvoMpNWapoWfX7cNn+zvx4voDKZ9jgxDUBCK6k7GItadGfE3y1BBmUPqpCGFGus5QTOOJ6Qpr5VjjhqBc9jrtmNCQmVLDVJoylx0ep73Xa2fpp0gsgXAsDrdDec5WfwS/XKGMVJg9fhBmjKrp9WsRBJFbovEEP6lK5Xc50BG0fI7ucAx72tTb9c8j9qnRq0HiiRopNYQZpNQUIWHhSy9WDuiVGsNmYaLUpA1qWOVTee9VGkBVagDtepuFss4/vb0tJ69FEERuCWRYbr0/Rbdf0U9j9jwh8TViuhS6cFs4ljBNgREDGwpqihAxqGkXghq9p8ZY/cSCGhsmDFaDGlmWLV+LVz6V9d5PAwB2m8QDG3G94iRwpWMoTecliEJDTBWlaoyXKqgR/TTiY/jzpjAK60/UWikFReigoKYI0QQ1wpdan34K689ykhuC12nHqLoyOGwSApE49nWE0BGM4uGVO/D8x/s1j9FXPuUC7qsRghpRSk7IwEMrd+Ts9QiCyA1ibxozlYTtManmMhmCGosqTbPb9EENdRUm9JCnpggRp2u3+a2VGmM+Wnmc22mH027D6EFl2NLUjVueXo8PtreiOxyDTQKOGzuXVzqJ3YRzRYXHgQOd2rLuVj9ThFxo8Ufw2Ie7cd3cCdyDoyeT/joEQeQWUalJ5anpDsfQGYoaOooDao+aMpcd/kg8ZZ+asEUKnUFmYUIPHRWKEFGBEdNP+iGRVpUD3qThl5mFX9vQxDv8JmRg6yF1ejdLC9XmKP0EqGXdnRpPjfI6px8xBOMbytEdjuGxD3ebPn7t7nZM/fHLePC/5L0hiP5Eo9SYdPsVAxQztUaWZa7UTEvOiUvVp8bKF8hIZxaOxRMp0+tE6UFBTRFimX5KBglVXuXsSG+yCwmeGgA4Y8oQAMBxY2ux/JJjcOKEQQCA7c2qebglqaAMyqlSo6xPHJXANqdB5S5cOnsMAGD5OzsQixs3zo92tCIYjeO9bTSllyhs/vz2dvziPxvyvYycEYwKnpoU6ScA2NdurIA61B1GWyAKmwRMG6EMw9UryqlmP+l72qRKP+1tD2LOPW9gwfIPLe9DlB4U1BQhmvSTENSwEQn1FYqqYlUOyUqzzztqOLbdeRb+8Z0v4OSJDbwh37ZmValp5XOfcuipMRlqKb7OV6YPR43Pib3tQfzn04OGx7NgyGwuDEEUCsFIHD97/jPc9/pWNHUaVYvbnlmPeb9+yzD7qJARlRr9SROgrY4yU2qYSjO6rgzVPmVP0asxohJtCHgM6Sfzzy4aT+DqR1djT1sQb28+RGrNAIKCmiJEq9QYS7rrk34Ysd9DPCEjGle+2F6h34zNJvHf2biEbUL6qbk790FNpUlXYaYI1ZW74XHa8ZXkXKl3tzUbHs+8Q71p004Qfc3WQ928+61Zs8nnPzmAjQe78MbGnk+77m80nhpdwBFPyJoTrn0pgpqJQyrgTSrGVt4/QLuHAWZBjblS84v/bMTqXe0AlJR6b+ZUEcUFBTVFiGieE4MadrAflFRqxPuJAYBVE72x9UpQs71Z9NSw9FMuPTXG9BMfxZAMnoZWeQAAnUHjwYArNSZnigRRKIjduk0rhZIBwn83GwP3QkXrqUntd9lvkn5iQc1hgyvgddlNn0f8rCKxBBIJVWXRp7zMPDWvfHYQD7yl9dt1mwSVRGlCQU0REombp5/0Sk0war4BuR3m/+1MqdnZ4kc8IUOW5b5JP7lTp58A1Uxsthl1UfqJKAI2HVS9aQHdwViWZQSS38m3NzcXTXokVZ8a/Xs8YJJy25hsvDdpSAU/uUrVp0Z/OaQrdtArNXvaAvjeE+sAAJfMHs33GjEYI0obCmqKEHH6tib9lDzYM0+N2WA4t8OmSTmJDKvywuWwIRqXsbctiM5gDLHkWVIugxp99VMiIfPNqY4HNdbTvJkipe/DQxCFxGZNUGOsTGRxzIHOkKbisJDxCwFINC5rjPz6IEdvFI4nZN5NWEk/pVdqlOcVxiYk7zu0WlFyxZYWAPCbVzajIxjFkSOqsPjMw1HmVl7DT0rNgIGCmiJEU9KtUWq0RmFNbpqd4bis5zfZbBLG1Clqzdbmbu5zKXc7cjL3iaEGLMpG0x6Mcu9BTTKoMWvQxyCjMFEMbEmRftIHOW9vPtQva+otAV1woJnTpE8/dYQ0CtTu1gBC0QTcDhtG1ZXxvchY0m3to2G/D6/2AjAqNWxQ5pVzxsPlsKHMba34EqUJBTVFiDb9JHhqdEpNUKPUKI/xOFIHJ9xXc8jfJ433ACG1lAzCWOO9Kq8TzmRDvQoTMzGDjMJEoROKxrFTGPWhT83oL7+9JTe+ms0Hu3DTPz/uszEj+nWLwRq7jamtgUhc04uKBRwTBpfDbpPgs/DUpGq4x34fVqUENXpPza7k+x49yAcAqODpJwpqBgpFFdTs3bsX3/zmN1FXVwev14upU6fio48+yvey+oRoPIGX1h8w7cMQ1smxoWgcsiwbPDWiyY5tHKxHjRXMV7O92S803stxUKNTYZq7jaMYKkzKvhkseAuTUkMUKFsPdUO0yRhSLLrL721rRdSkJ1O2/O29nXjso9341+o9vX4uM/RBjWakQfK2mjIXqn2KGiuWdbNOwhMHVwKApacmVTqK/T4sqdSIQy07AlFeHt9YowQ1pNQMPIomqGlra8Ps2bPhdDrx4osv4rPPPsMvf/lL1NTU5HtpfcKL6w/gir+twi9e3mi4LaLb/DqCUYSiCcSTAcygCjU4YOXf+h41VmiCGn9uh1ky9OknMzOyWCGlN1GyQCcSV98zIxpPYNkbW/HJno6crpkgsmFLU7fmsjH9lPSGVHlQ43OiOxzDut3tvX5dpoyYKZy5wK9Lm2lTQ8ptXqcdQ5NKyr4O1VfzcfI7OXV4Jb+f/jkAk0G8Jh2Ga8tdcCVVXTbUkqk0g8pdPJhJFdREYgny5ZUgRRPU3H333WhsbMTy5csxa9YsjBkzBqeffjrGjRuX76X1CaxZ10GTXg96haItEOEHepsE1PrU4IBtAjz9lCaoYemnbYe60WqioOQCfWVTi2lQo9wnIWvPDmVZ1mxQ+k1p5dYW3P3SBtzxwmc5XTNBZAMzxDKM6Sflb7jM7cDx45VO3rko7WZpFr1nJ1cEwqlUFGWPUYIaxcjLlBpZlrFmVxsA4OiRyomolaeGPafTLiVvF5Vp9TVqypQTH6Zms6BmZK2P37/cIv2USMg4+7f/xWm/esu0azlRvBRNUPPss89i5syZuOCCC9DQ0ICjjz4af/zjH1M+JhwOo7OzU/NTLHCFxeRMgh3IpWQRU3sgyiufyt0OOOw2fhbDNgz93Ccrxg5Sugrv6whhT5tyltVnnppwDPGErAZPQi8cr9MOe7JKSwxiApE4RHFGbxZmxukOk/42BNFfsMon1j4hENUpHMkDt89lx4nJoOadHPhqWPCkD6JyRWqlRi1GYEEN61WzsyWAtkAULocNhw/VKjXRuKxJvTGjMO84bDI2weu0oyZ5e1vAOqhh1U/dumCsKxzD5qZu7GoNoKkrnM1HQBQ4RRPUbNu2DcuWLcOECRPwn//8B1deeSWuueYaPPzww5aPWbJkCaqqqvhPY2NjP664d4R1CosI69rJGuK1ByJcbmZpGzfr1smfJzNPjZgPX508s8q1p4aNSQCUgKVFmNDNkCTJtJ+NXkY2VE4kL5OsTOQTln46YphyALdKP3mddsxOBjVrdrebesiygQUdfRXUpPbUiOmnZFCTVGrW7Fb2kqnDq+BKBnqiasz2qYTQlbjGZ5xhp1Zx2nhQ08qVGqUsfmSyghNQ0096pcasRxZRGhRNUJNIJDB9+nTceeedOProo/Gd73wHl112Gf7whz9YPmbx4sXo6OjgP7t3m099LkT0Xhiz2wZXKkFNWyDKK4KYCsLOgkK6oCZVSTeD+Wo2JzfmXHYTBgC3w843tq5Q1DT9BKjSsVhBofcKhPXln8lNl0zERL4Ix+LY0aIcYI9srAZgXTXkc9nRWOvD6Dof4gkZ721r7dVrs4O3WQfjXMCe32eSOmKBic+lemp4UJMcWXB08vMAFBWLqc2sU7AYwFR7jUoN+93jtPP9ImX6yWUe1IidylsoqCkpiiaoGTp0KCZPnqy57vDDD8euXbssH+N2u1FZWan5KRasgpp4QuYN8QZXKGdD7YEoP/NgQY2HBzU6o3Cakm5ADWoYuVZqAHX+U3c4JqSftK+jln6rG1A6pSYYtQ4GCaI/2HbIj4Ss/I2PTqoGVn1qfMmD7uwcpaBY59y+8tSw98G+q5r0U9JT4xHTT0mjMA9qRqqFHZIkGczCojJdxZUaYy8c0VPTmmxrYRrUWHQm1yo1lH4qJYomqJk9ezY2btRWAm3atAmjRo3K04r6FpY+0aefxIFxDZUsqIloPDWAmmYK6TYLdwZN9Ni0bkauPTWAtrme1SiGSl2VFKANcACzoIaln0ipIfIDUzgnCPON9EFGQFA1AGDWmFoAwPq9vavaC/Rh+kmWZZ7eYhWRLJABVN+Q12nH0GpVqQlG4vh8v+JnPGpkteY59b1q2L8uuw1lTA0y89S47Lwgoj0QQTSewL52RRUaVSd6aqyCGuPcOaI0KJqg5vrrr8d7772HO++8E1u2bMGjjz6KBx54AIsWLcr30voElj7Re0PEy2r6yeip0aefMjUKA0alJtcl3YB2DIJV6bh6liV6arSeA33Qp0+3EUR/syVZ+TShoZwftFOlnwC1t1R7sLeemr4zCodjCW7SZ/43TYNP4T0NSZ5wBSJxrNzajFhCRkOFG8OSCg5D36tG9P6ZVUfx9JPDzo3Erf4I9rUHEU/IcDts/LMErKufOgWlxmzS969e3ohLH/qQKqOKkKIJao455hg89dRT+Pvf/44pU6bg9ttvx7333ouLLroo30vrE5jSoJet2fV2myQYhVVPDQsE3FbppzRGYaB/0k8stdQRjPKuyFbpp64Unhp9dRj7vGIJmTYkok/oCkXx2oaDln9fbJDleCGo0fdiYWkibzL9VOlVgvyOXgQ10XiCK7l9EdSIgQEbZ2LmqfE47fC67Lzg4PlP9gMAjh5ZDUnSzp0zpp/U53AnU+XsOy7LMk9FeV2CpyYQ4amnxlqfZradqtToqp+EfURvFJZlGX/873a8tqEJWw5p+w0RhY8j/V0Khy996Uv40pe+lO9l9As8/RQzTz+57Kr7P5WnRr9ZZKLUjBaqByo8Dm7qzSVsnXvbgryBXo0vvVFYLyOnaqkejiXgsBdN3E4UCb98eRMeWrkDd3x5Ci461pj+3pyc+XTY4Ao+9sOg1ES1htuqHAQ1AY2hNveeGrFiq8xERRFvB4ChVV60B6JY8dlBAFo/DUOvxoR0gZHyXpQ9LxqX+V7hcdp5YNXmj2JnixLUjBL8NABQbjHQUvTU6NNP3eGYmg7rI8M10XfQjl+gMEUmntD2cGDBjttp42dCmvSTm1U/mXtqMhlM6XXZ+cC4XFc+Mcrdytp3JDcjs+CJdxVO6amxHn5HvhqiL9iZrGx6c6NxCGUkluB/0xMGC0qNRUk3D2qS3+VILGFInXaGojj912/ix89+mnJdom8nkBydkoqVW5vxxEeZV4T6ecNAOzwm7yuk8wkxszDbm8TKJ4aafmKKstpcz6NTasTvttKnRt3/dgtKjYhVSXdnCqXmkNC3Rq+wEYUPBTUFitkQN+X3pOHXoQY17cEoVzBYIODRe2pYLjqDkm5ATUH1ReoJUJUadoAw61psNv8p0z41ZrcRRC5g6dIPd7Ty2WqM7c1+xBMyKtwODKn0CJ4anVGYqRrJ28tdDrCsiV6tWburHZsOduMv7+5AU5exwzjDL6RYZDn9FPurH12D/8ti+CV7fp/LYTriQGy+B6hBDaCky6eOqDI8p3X6yaYWO+j8NnabBKdd0vSpMat8AoAyVybVT9ZBDe0hxQcFNQWKqDKImxOb++RyiOmnCDe+8eonh07WjTGDXWb/5SyoyfWIBAYr6WZntXUmipB+nAIAXuXFMPSpSaHUyLKM5e9sx7tbW3qxcmKgw7pWtwWivNKJwVJP4weXKyXLGRqFbTbJ0lfDjKwJGXj+4/2W6zIGTtYpqI6g2h9qX3vQ8n5mz+dz2Q3pbeV2NXUEaIOaSUMqePm6CA9qks+t9+UAglIjpLckSeInXOFYAhuTE8DFyidA3Q/DsYRG8RaVGn2fGrHDsFjdRRQHFNQUKGLzOI1PhCs1qhEvGpdxMDkrijff47nq7AZaMmaOVvLfk4ZU9Pg9pIIpSuysyEwRMjMKpy3pNpHDGZsOduMn//4MP3jqk16snBjoiGf2H2zXBsisdHl8si0CO5CHY9rhqwHefVc90Fv5atoD6uVn1u6zXJdfZ4ZNZRbe26YGMpl21GXPV+Z2GKorAWOgxhrwAYpJ2AyvS6/UqGlydmLGnjeo28N8LrWJ57bmZDdhi/QToE1BdQqfcUcwqgl4KP1U3FBQU6CIpdvi70ypcTts8DrVL/XuVmWTUquf9LOf1Fx1Jpx75DCsuP6LuHbuYb15G5aIoxIAc0WI+W7M0k9mw+4A9X0CRqWGnfE206wXoofE4gnNWf5729UOwLIs4z+fKqbYY8fWAVAP8IC5qiHezoOagHVQs3Z3O0/Z6tErM6kOyHsFdSbTjrqiUuN1WntqvCZKzdGNRpMwYPTUBMX0k+WJmbK3SZLEfTUMvafG5bDxPVKj+OpOjsSy7kPdFNQUMxTUFChW6SdW7eNy2DRfavblYw3r+FkOa0aXpVIjSRImDK7gQyVzTYUuqEmp1ISNSg3raaMv6U7lqWGfRVdykCZBZIteRXl/Wys35G482IUtTd1w2W04/YjBALSjAMSgQxwpwLBSavR9VJ61UGv0vpHUSo3qo8m0+ZzqqbEbAg7x9binpjq9UqMveQ8LgRFLleuNwuKJmVgxObjSbbq/qb1q1M9DP2Orza9ebupUgxp9dSVR+FBQU6BogxqjT4RN/2XzURjsC6xPP6kmvsL4L2fpJ0YqT42mT01y466vSAY1KdJPeqVG3KB6OziQGJiwAKMsmfpo7g5jezL18dw6xe9y0sR6fnIhSRJ8JqqGPgAA1KBG34CPeXgmDlZSwU+v3Wta2aQPYgJha0+NqNRkOiaABWVl6YzCydtG1Hgxrr4M00ZUGXpfMaxm1HmcdsvGfOJnJp4M6VNPDHVSt5B+0ik1LcJnoFFqqKS76CiMIxxhIKxRHASjcEz11ADgvhoG71OjO8thG4I7g9lP/UG5O336qcJtLOlmwcigctb8y9oobKXUANqBdgSRKazyqb7CjaOSJcrvb1fUmuc+VhSUL00bqnkMa7Cn7SOjVhIxrJUa5fL/HNMIt8OGrYf8+HRfp2Ft+rLllEpND9JPXKlx21N6aljQ4bTb8J/rvohnFs02NN1jeF3Wvhl2m9qI1NiWQlRqRtaaB05lJkMt2T7COhyLvqKmTrXCjNJPxQcFNQVKOqWG5YkNDev0Ay35WU7mfWr6g8os0k/BaJwb+djZFuufk675nohYydBJSs2A54Ptrbj/za1p+7mIsINftc+FY5Pzmj7Y3or1ezuxoyUAj9OGuYcP1jxGPypBlmVB9TAqNZ16pSZ5ubHWx5/72XXGFJRBqUnlqemRUVhVapivhR30o/EEH7TrE8zPDrvNMqABzJqEpjcKa9JPZepJnZVSox+VoPQCUl5nVLLRqPgZNJOnpqihoKYAiQkbBKD1jfDmeyz9JCg1LoeNKzGGckgT6Taf6NNPZkGNaCbuDsUgyzJXbQZVGD01iYRsGQzqL+sPHMTA47ZnP8WSFzfg3W2Zl/izVFBtmQvHjlHMwO9va8G/kyrNqYcP1lTcADA04BNnKJmln4zVTyyQcuLco4YBUHw1+h45fr1ROEVJ954eBDV+QV3Sp4bEg78nixS3Po0lGoVZqjyVp6ZWVGrqVA+PiH6opZh6ZiXgzFcUiyc0yhX1qSk+KKgpQCK6mTJm6ScXD2rUL3WFsJnyuSnRBBIJmT8u0z41fY3eKGw2CdxpVxtwdYdjCMfUYE9VaoQgxjD80zo1RUoNwbwkn+/vyvgxLBVU7XNi+qhqOGwS9nWE8I8PdgEAztGlngAYJnWLPo2M0k/Jg2yNz4k5E+tR4XHgQGcIH+xo1dwvkGFJdzAS1xy4M00/BXlJt91Qis1us0nKCJdM4YGLyTgXt67XVlgIeBg1ZenTT+zkyM+DGlUlY948Fti1+CMQhTvy1BQfhXGEIzSELSZPA6JR2OipEQMFLg9H4pqDfaEoNT6XHWJhlVXnYqbodIaifDOSJNWDI743w/DPqPVl8tQQLAjYfDCLoIYHGC74XA7eJbczFEO524E5ExsMj9FX+DBFxeWwaaoLzYIasYS82ueC22HH7HGDAKg9cRh6pcYqqNmra7bX5o8YVB8zWFAgdhRme5XoEUqVbtLDnoetNSymn4ShvLIsGzw7gN5TY5F+cumVGrX7Ott3WFBzSNfugdJPxQcFNQWIXmHQBjXa9FONJqhRf+dGvlhco/R4CsQoLEkSz3VXuB2WBmamPnWHYnxTKhfkb/G96TegVEpNbwYHEsWPLMs8CNiUTVAjpJ8A8BQUAJw2ebCpZ4012GMHbn2TOoZZUCP+Xp28vTapaur/hlmQxno4WXUUZkENq0iKJeSMlMuAqNQk32cknkAsnjA0xssUqzSWVzAKA8p32ew1mFLjc9l58YAe/aRu9l4rvY60QU26URNE4UFBTQESTpFGiehLuoUzFbGiSDQKs83A5bDB1kd9Z3oCC8JqLTYj5T5qWTfz05R7HIbmgvrfzS5T+olgBKNx7mvZfLA7Y7OwmH4CwM3CAHDOkcbUE2A0CvPGe7oAwGxMAjMJV3gcfOK8VZqKBWmsh5OlUpP004yu8/GThkxSUH7eBVkbcIRiCaFEPbtDilVJt9tp06TKg8I+JnpqJg6ugMthwzGjay0VIv2kbuapqfA4+WfFghr9bC1SaooP4zAOIu+kVmr0fWqs0k9MqVGn/haKn4bB1ptqaGY5b8AXhS+cHP7ndhhmWwHGOS3GIEeofiKlZkCjacQWjmF/RwjDqs2NpiIs/cQMqseMqcWgcjd8LjtOGF9v+hjVKKwcVM161ABqoNQRjEKWZUiSpDEJM6yCGva89RVuHOgMWfpB9rYrjfeG13ixrdmPrnAMrf4IxpkvX33+MFNqHHz/Ud5XXJ3Q7czukMI8RUajsB0Ouw1Ou4RoXE4qzsagZkiVB+8vPtXQoVxEP6m7k6efHLx6qkWn1Awqd6O5O0xG4SKEgpoCJKWnhs1+Sn6xRaOc+MUWz4CynfvUX7Cghp0tmd5H6FVT5lKVGj7Bt4fpJ33zLWJgoe/psulgV2ZBTUAt6QaUAHvF9V+ETZK4eV+PfqhlMKp6U0RYsMJKjr0uO+90K3pHrEq//bzdgUvzenqYUjO82ofaMhd2tgQy6irsF8YkSJIEj9OGUFQ5aWIBlCdLzx5TdvQl3Wz/8jjsiMZjilJjEQzWpBm6q69+Yp9bpaDUtAUUXxELakbWetHcHSajcBFSWKfuA4xQNI7XNzYZDa6G1v8mU7rtxpLuSsFTI/aRMOvEWQiw9FOqSeAsUOsUPTVu1VMjflb6oMag1AifMyk1Axu9qXbzwW6Le2ph6SexP0pNmQtVuiaYIlbpJ/33sdzt4MZhpsLogyggM6VGuZzaUzO8xsu/e5mUdYsDLQFtOXaAKzW989Tox7mI4xh66tvhfWoieqOwqtTEk76iJh7U+Ph7I4oLCmryyCPv78Ilyz/Eg//dprleb04zNQo7jWMSRE8NU3JkWa30KRSTMIOnnzLw1HSH1aCmwmNuFNYHMYY0XkxUaiioGcjoJ1pnYhZOJGS1T40vtTogwlMsek+NLqiRJIk3pWQBC/u3JoP0k1/XmDK9UuMVjLLpRyWIAy0BnRpsEailg1dRxZTWE3rfDFdkhYKHngY1zCgsVj+5HXaNr4grNcmmfJR+Kj4oqMkj+5NnTPs6tCWWBqUmhVHY5bDxrqQVJuknQD3by1Ya7mtmjqqBTQKOGW0+wRdQ1ZwuoaRbUWqU9y9+VmmNwhqlhtJPAxmz9FM6ukIxbi6uziKo4WXLup4u+qAGMAYs7Ltrln6yMgqnCmqi8QQOJMcANNZ4+cy15jTpp3hC5kEFGzvgEZoKmpl4M0FrOBZT5cr3m3vnevEaPP2UPJERq58A9aSq1R/hc5+4UkPpp6KDPDV5hH1J9ZtPJkZhMX9f7XPBHwlqPDVOuwSbBCRkoD0pmReaUfjiL4zGV2eMMHgLRNhZVFcohgoPC2qcfLOLxmXEEzLsNskkjWfdxJCUmoGNGgC40NwdweambiQScsrqwFbdMMtM8VoYhc3+7o1BTVRzvdl9AG3Qwbptmx2QD3SEkJCV9PWgcnfG6ScxleVza5WaYDRumVJLh6gei8ERU2PEzuhqGj27fUw/pVusfgKg8RWxCd2s03AwGuembaI4KKyj3ABD342TYfTUmBiFhc2A+WrEPjWKkU+5D5PMC81TA5hv7CI8/aQr6RYlaPb5sM+T7T+plBvqUzOwYUrN5GFVcNltCETihqZ0erhqksaYqkfvqQnq0jgi+rLu9oDaTVh/n1A0wfcKMeioZ0pN1KhGsvc4rNoDm00y9Gmxgq3dbpO4n88jpJ96qqLYbBJXnQMRY4pJnf+UUM3IWSs1+pJu5d9KXqigfAZ72gL8fTTWKEFNQlZOnIjigYKaPKI/GDP01U/i5bDOKAwAZ00diuHVXswcpU3jsA2mjSs1hRfUpKNc7FPDPDW6klL958jOZFNVPwUi6pBMYuDBztqrvE6MrVf8E5ubUqeg2k1SQZmg75qbStXQqzDt3JisHYfCAnd2PzHoYOZX/dgEQPDT1CiVXiyoSdenRu0mbOeqhajU9KYYgT1GPNHg6SdX7wMn0Sgsy2qjwUpBqQGADQeU//8yl10ztoXMwsUFBTV5RG8cZLCDsdgVmN8mNKdiLDp5PN65+RRDSaqHBzVJT42z+P67uacmHBNkYwdswhkj8xwxsyI76KQyXAPqGRsx8GAH6TKXHRMGVwAANh5IXQHV6jcGGJlgMAqn6OlilX4SPTw2m8QPyKyKTww6fLoOxiK88im5V6jN51IbhXnlk6CsqpVLCa4UZRtwiI8R1SJVqel9FSfz1CRk5XnE6idA/f/ccEAZO9FQ6YHTboMjmYoks3BxUXxHuRIipJubwmCSchWXmdXbIzFj+skKFviwDbIQ00/pUDsKC0bh5HX6rsJGpUZnFNZtTlTWPXDpTh6Ey9wOHNZQDiD9DCizVFAm8D41yXRQIGydfmKp5M4U6SfAGPyIQYc4bFI/00nsUQNoTbKpuirzoMmtrtkrqijJxpe9UWrYyZfDJsFpkuLS97DJFEVdUn7vDsf4Z6tvKcHK+ln6Tl9uThQHFNTkEX0XTQZLN1UJuXN+m4lR2AqvTqnJJBAqNESjsNinBtBueID6ObIDgJi2k2XVSMkUHjILD1zE7rhMqdmUJv3U6u9Z+snn0h4cM0k/sWCG96nxukzv16FXatx2TbCkn1wv9qgB1AN6NC6jS6gI6wpFsbs1wC8zdUlUarxCLyy1oWDPlRrWrVn0zHhNfDvZemokSeLr9odVpYZXPyXVKra3sj4/HiG9RhQPFNTkEX4wtkg/mSk1+jEJqeDpJ38xKzXJjsLhmEE21ncVZmeLTKoXlRrRX9NQqWxaVNY9cBHTTxOHKEHNlmQFlBW88V4Pgxq1o3BmJd2iOlFdloVSIxz09SkoffrJ47TzlhBiV+Fr/r4Gp/zyDWxpUtQLFgSKa9YEHD008YrPw71/wnOw73hXKIZ48v+mJ6/BToSau8OIJZ/HqvknC2r03Y6J4oCCmjyilnRrD67sYFxpGtQkPTUZBTXa9FMxG4XjQgvz8uToBPZ+2GfCzkqZhK8ZoSBs7g3JTYuUmoGLX0g/jaz1we1QWv7vbgtYPoangsp6ln5i5cFWzfcAbbDCTMIOm8QVS8P9kvcRRxjYbJJqThbMwomEzIOaETWq/05NQSnfr2g8gXe2tCAal/HB9lbN85eZDM3tTZ8aQP182k28fx5daqqnr8EqoPYl379NAg/m9LPneFAjDAUmigcKavJIUHfmxjAqNcbme9mkn1jaJtv+DoVAmcsO1jqEfU7lHm36iaWZ2ObDpHpNY77k7067WsZKZd2lz9Nr9mLZG1sN1/t5+skOu03CuHrFV7PxgHUKiqWfsmm8B6hGYVlWvstq+sloFBZLutuEYZb6Pinq/ZhPR02nKa+p9fEAQLM/jEgsAZukDIJksPQLU2q2NHXzcSzMPBvge4iooqjBWqqGgulgz9OaDNDEoIWduDCTtt0mwWnPvmcMU2oOdCiNBys86meaLqghpaa4KL6jXBEQiydSmu4Y7MsSjcua8mK9pyYSTyCekCHLspB+ysQorL1PoQ20zARJkjTjHwDRU2NuFGZKDWvMB0Ajj1daDAQkSoumzhC+98Q63P3SBuxo9mtu6+bpJ+Vv6bDBSbNwk3UFFFNOshmRAECXDoql7FNTJQQrZnOfjPczKjWAcYgmoJqEByerexj6Bnyf7uvkt7EyZz9Pb5kZhRO9U2qceqXGGDjxXltOe48a4bFgbz8PatQ9pU43pqVB56nRV1EShQ0FNTnGH47hhLtfx+V/XZX2vmJaKWiSYhK7iIZjcX72BGhLuq3Qp5uKMf0EaJsKAmpQwwI7psLogxpA/SxFkyEvh6X0U0nzxKo9PKht0ZUss5Qv+1viZuEUFVCicpINdl2DOa7UmAQA4gRuFkRVe42vZ2UUZkFama6MHDD6aRj6XjWfCUHNxgNdyZSZcbK4qYm3F0bhVr8x/cTMyG0mAU82qEGN8hmIe4rXadek81VPDSk1xQgFNTlmZ0sABzpDeH1jE99QzYjFE5pOlWLeVk0/qRtIKJrgqSdA23zPCn26qdBmP2WKeFblc9n5JGOjUZgFNeqZF7tNLAdVlRoyCpcqiYSMv3+wi182Dn9MpkuSB7tJSbPwut3tpiqrLMv8wKpPV2SCz5VZqkZUZ5mqkJlSo00/mSk1+3SVTwyjUtPBb+sIRnGwM6xJ1zG8OUo/qZ4aM6Ow9raeptD16adKYU+RJEljFm6oUFJzlH4qTiioyTFMTYnGZTR3Wze0Cum63QZMghqf26FpACVW8GRkFDYoNcX53y2mn8wmkTPFi/1b5rLzoI+biIVBeWxDI6WmdHl7SzP2tKljD/RBjdoeQPkbOnZsHVx2G3a0BLD1kDEF5Y/E+UlIttVPgKpwBCJxtTzabfTUlLsdPGjf1eJPvp61UsNSqMzzwoIOteJKDdzZXKPBlaqfBlDTL6xXzWf7FaWG7TEbDnSaKjVMLQ5G1KCmJ+knj0GpMaa42ntZ7MCNwoKnRoSZpW2SGrR6yChclBTnUa6AEb0xqWbJ6Mu4tUGNWuEkSryiSTiTvLJeqi3Gkm5Aq9SIQzv5BF+m1AgpJrYhq0qNuumSp6b0EVUaQK0SYugP0uVuB74wrg4A8PJnBw3Px3qouB22Xo8CYAqu2fNIksQDlu0tSiWWWQdjK6WGvR99GTkAfpI1SOchYUbh5u4w9rQF0RWKwWW3Yc7EegBKCipg5qkRpo/3xlPj06V5xOdgKeZUn1kmsIpJ9hmISg2gfgZ15W5BCSalphihoCbHRAU1ZV+KoEbfelv84oSEoZVuwazGTcIZpJ4A4wZQjEZhQHtWVaEpKdUZhYWmZnoVx9xTQ+mnUqSpK4QVycBkRnIeWoeQagzHVNVFVEtOmzwYAPDypyZBTS9ST4B64G4R1FufxfeRBSw7k0qNmYfH2KdGq9R4BWWI0ZysbhqU7JjLENNPLPU0YXA5pgyrAqANanzC58X2l65gFCzT3qOAz1DQIHhqcrSHMUWOZRYrdT4l9hkwk7C4LgpqigsKanJMOJ5ZUKP/ogTNlBqnTT1wx+Ka6zNBn6IqVqNwuZVSo5uNJfpm2HtngaC2+imZfiKlpiT556o9iCVkTB9ZjWNG1wLQpp/E3i2i8sCCmrW729HUGdI8p9kMpmxgB0hWNu2y2+CwODlhB1yWPtN3EwbMjMJapYa9r6CQflKVGm1QU6sJapTU0xHDKnlTws8PdGlmS+nfU2sve8jovX4aT41uD+vJ8wPGVF+FQalRPoN6Mahxqek1ongo2qDmrrvugiRJuO666/K9FA1apSZkeT/9F0VT/cSVGptmFABPP/VQqSnGPjWALv1kotSEo0rJO/MzeZx2g4oTEoaEMqWG+tSUHomEjH98sBsAcOGskYaDP6D6adwObWAxuNKDI0co6sQrnzdpnpeln2qzbLzHYMEACyxSKRpszSzlkspTE0zuC1ypSVHSnS6oadEENVWYNKQSALC1qZt/fmYDLZmJN1Wglgp9oKLpU5PitmxIF9SwirDGGp/htWigZXFRlEe5Dz/8EPfffz+mTZuW76UYECuaUnlq9F8U0dDH1AXx4BwW008ZfrH1ykwxzn4CtCknlhsHtB2Fxc9TUWrYbdrGfB6nTTVZklG45Fi5tQW7WgOo8DjwpWnDTIMav66cW4SpNSs+O6C5PlXPmExgCgpLAaWqEqrSpUbMXrPC4+BDGjuCUUM1l95TE0/I3Ig7qEL7fMwoHIklsGpnGwBg8rBKjKjxwueyIxJPcPO0RqkxKCw9O5zoAxVxfzOemPU0/aT9v67UGYUvmDkCPz5nMq46ZTy/Tj9bjigOii6o6e7uxkUXXYQ//vGPqKmpyfdyDETixhJKMzJKPzlsghk2rlFwMqF0jMKCp8ZjrL4Qm38BTOEyb8znddmF8RMJwyRvorj5YIfS1n/eEUPgddkNVUKAWM5t/D6cfsQQAMA7W1t4ygUQ5z71TKlh3z3WLye1UqM9AJuNZbAJoxM6glGDUqNWWynXt/ojSMiAJBmbB/pcDs1IFUkCDh9aCZtNwmHJ/j1mHqRc7S96Bdmso7DVa2aKUalxGi4vnD1GUxlm1afmwf9uw/nLVtJJUYFSdEHNokWLcPbZZ2Pu3Llp7xsOh9HZ2an56WuisZ4pNdrme6pRWPSNsIApkxEJgEmfmqI1CjtMfxfPpIKCEmOzSUalRjAKV7jVs9wuMguXFF3JAw0zfJoqNbpGdSITGsoxqs6HSCyBtzYd4tfz9FOPlRqtpyYbpcaqhLzKp743ffUTr0xKXs9ST7U+l2mKqK5MTUmNrivjysbhQytM34f4Guptxs8zE/T7knb2k34P62mfGu1r6NNPZqhGYW37jUff34WPdrZh5ZbmHq2F6FuKKqj5xz/+gdWrV2PJkiUZ3X/JkiWoqqriP42NjX28Qq1RuD0Q1Zztieijf01Jt8ZTo6oRWSs1Jd6nRlSxQrpyUCulxuNUBv6x5yGzcGnRnQxSmaHcLKjRdxMWkSQJpx2erIISSrt7m37y6qqffE7rg6o+qNFf1l/fGYwa+tSwf4O6oEbvp2GIowImD63kv08crA1qRMXDWLXUQ6UmxfP0ladGX/1khlWfGtYzR+yDRBQORXOU2717N6699lo88sgj8Hg86R8AYPHixejo6OA/u3fv7uNVao3CgNqWW08wor0fO/gq853UKiexNDmbuU/K49X7Oe1Sj0x8hYAoFZenST+xTc+o1CQ0t1NZd2nCTMAsNWNuFDaWJ4swX81rG5p43ylmhs12QjeDBTHNScUnE6MwoPy9WgUL7H7twYhRqdGVdPOgpsI8KBNL1ScPE4KaIZWa+4lKjf7kyttTT43eN5Mi/dTToEYfwGan1KhBjSzL/G+JgprCpGiOcqtWrUJTUxOmT58Oh8MBh8OBN998E7/97W/hcDgQjxu9EW63G5WVlZqfvkZsvgcAey0qoKyUmlhC5j0f3A67psFcNhO6gdSbQzFhXf2kpuZ4+smlVWrCum7DPKihBnwlSZeFUhOMqi0R/LpuwnpmjKpBjc+JjmAUr36uqDXMZNuTbsKAGgyw73Dq9JP6Gqk8POy9sXEKgNBRWGiMBwDNXcr6xTSTiBjUHCEENWx8hPo+1O+fzSZp0kE9TT/pVSvxOZ12iTfDA3JnFM4kqDFrvtcdjvGqtD1tgR6thehbiiaoOfXUU/HJJ59g7dq1/GfmzJm46KKLsHbtWtjthXHQjuiUGiuzsJWnRj8KQUyjiAbiTNDmpgvj8+kJ6T016ZUa0XMDqB1Fqay7tOjiAYtywNdXCQHiRGvzA5vDbsP5M0YAAG5+8hPsaQvwKdE9DWqyqeIRlZpU6S4e1CRPnCRJPXnh1U/JzyNt+slCqakpc3F/ktth0wQYQOry60wx+mbU55EkSZM2z5VRWF/9ZAY3CgvpJ3G/IKWmMOlZaJ0HKioqMGXKFM11ZWVlqKurM1yfT/RKTcZBTfKLEzZU8ahqhJp+yr76qacGu0JAk37SlHSr85306SVjnxrVUwMISg1VMJQU3cn/Txb8siqhzlAMncEoGio8glJjvf197/SJeG9bKz7Z24FFj6zmE6x721GYYWZSZohBTap0VyVXapQ9xpf0iwFqao0pwIfSpp+UwKW+ws0HOjImDqlAU1fYdFaV8n1iwyZz76lhz+vvxWwpAHDabXA5bIjEEnDZbRkFR2Z9atoD2qBGluWMRtYQ/UfxHukKlEiy9JH9nVtVQLEgpoJvPspGG9bNdzLrU9OT9FNPN4NCwNIonHxP4WhCU90EqH4is47CgOCpoUndJUW3ScAiVgkBMJ04rcfjtOP3F01HldeJdXs6+N+R2ciCTNAHNSnTT8JrmHUT5vdLBjWsyacYdOjnKVmNSGCMSE7uPqqx2nAbS0GZrVncV6zGPqTDWP1k3V+rN20p2N9EJqknwDyo6dQ1cSSlt/Ao6qDmjTfewL333pvvZWhg6adhVcomYaXUsM2GTYdlZYN6NUbTpyZLo3CqKoJiwuVQJ2uLVRpuQY0J6oIaj0Ov1GiVHGrAV9j8c9UenPrLN7DNZGJ2Klj1k3jgMo4USJ1+YjTW+nDv14/iJygOoWouW7y618o8/ZSJp0bZY8wqk9jJUnOXotTUWwQ1844Ygp+fPw0/PvcIw23MLGwW1JhN1M4Wp90Gp13wzaQq8e6F4syC2EwqnwA1LRaMxiEnh0bpgxhKQRUeRR3UFCIs/TSqTmm3bTUqgR2EWY4+yJUa5pthaRQxqMmuT407B7noQuE3Xz8ad391qqY5lhjwicMsAUGpYVO6dbfT/KfC5vmP92HrIT/eFHrFpCOekHmaQqPUGCZap08/MU6e2ICrT5kAQBmj0NNUQzZKTZnLzr0rqTw87H2xxoDic7LfQ8kRIuk8NS6HDV+b2cjHBYjMmViPCQ3lOO+o4YbbxECmNypKqlS5+Ly92cdYyi9bpSYhg49gadftF7tbySxcaBSNp6ZYYErNqLoyrNzagv0dQSQSMs91M5iCwHL03Cis60Uj9qmJZOmpUZrQ2RCOJYo+qDl5UoPhOtVvJBqFlc+GfUbMS6MqOcwoTCXdhQw7iLQFMg86u4WeUOVmSk1AP/wxs+/EtadOQF2ZCxMayjNeix7DfKMUKpEkSajyOtHqj2Sk1DBEn46oQgUiMe4JsvLUpGJQuRsrbjjJ9LZcpbi9TjuvXDMoNY7cvAYLZjINasQ9MxRJwO2wk1JTBJBSk2OYUtNY64VNUtqLs7MkEaYssDMxZuhT5zslD86mRuHMv9j6dEwpwQKUeEI2bIgevVITtTAKk1JTkLAAnnXyzQQW1LgcNs13hJVIdyT9U5kYhUXsNgkLjh+N48cPyngtegxKTZqDMwtYMlFq+HO6tWoHE5X2d4R4GbJVSXdP8eQqqBH736QYv9AbNYil5zKpfAKUtJgjeTLKToraA/qghpSaQqP0jnR5hp1hep12DEmmSszMwqxah3lEWJDDDr5m6ads+9Qoj1fuW6xzn1Ihbqis5JaVrlsrNcwoTCXdhQz7W28NZBHUhLSN9xjG9BMzCvefUK3376RTiZhxd3iNMR3ESKXUSJLEAyeWIqnyOrPaOzJBTBX1Zo/xpkg/uXOk1JRlaRQWX4/tH+xvaHClEhySUlN4UFCTY8TAY1g1MwsbfTVBq/STwSgsjEnIMv0ECMpFETffs0L8HFgb+3RKjaH5HhmFCxL2t96eTVATVv4vyz1pghrdSIH+INtp03d+eSru+8Z0HDum1vI+BqXG8BrK57ArGdQMKu9ZOXoqcpZ+Sq7dJgEuu7WnpjevUc49NZlXsLGTJHbS2RFU/h6nDKsCQEFNIUJBTY5h6SenXQxqzJSaZFBjSD9pG+xpjMJMxcmiAoA9vhSVGkmS+OfEZGG1+Z6q1MTiCT5l2DAmgUq6CxKmeLb6Mw86eTfhdEoND2r6U6nRG4XTV16dPW1oSmOy/uCsfz/sNXe2sKAmt6knIHepIfFkRP+eNc33evEaU0YogcjU4VVZr4spvuxv6IjhLKgJ8MooojAgo3COYQdPlxDUmKWfePVTUqmJxJQqBW4U1isOsQTf6PVnMqlgz5NNIFRMeJx2hGMJvtmwjVXTw0bo0qx6apLVT6TUFCS98dRYBTWduuqnVA3wcg0rW2b7Q6Ym5VTYbRIqPA4ezFlVWO1u7cOgJgcl3eLzmCkxmsqoXijOFx83CmdNGYK6LD4HHtREtJ6aycnp5f5IHG2BaI+bMhK5pzSPdHlETD8Nr1Y8NWZKDZMza4WOocGosWuwV6PUaAOeTGDVQKWYfgLUz4mln9j7FJUasXkWu56lnyKxhKG7M5F/RE9NpmfCXSY9agCtUhOLJ7ifrT+VGiB3AYCImIKyUmr6Mv2UK6OwR3cyIsI+K7tN0vSz6QnZBDTiuvSemoZKDx8fkcos/Oe3t+P1DU09WSrRQyioyTERs/STyaRu9iWp9rl4lUIgEjNJP/V89pPy+NJNPwHq+2Olv/rNMRxNaOY+sdL6cpcDrMqe1JrCg32PIrEET82mQ228p03LiEFNQAhg+9NTA2hTTrlSicSgxirFtasvlZoc+V28KRRlj3CC198jCdhJIQ9qkvtMldfJzdxWvprtzX789LnP8IOnPumHlRIMCmpyDDvDdNqllEZhpg74XHZB4lTNwB5d+ikUFdJPWQQ1TIrvaSfUQocFfRFdx2C2OYYFpUY8C7TZJH7wI19N4SEOhm3NMAXVlSb91BGMcj+NwyZllcbNBb4c+U9ENEqNRdditqcMqsh9UCP6XXqTUkuZfkqh4vQ1fFJ3RPHmsb+xaq8TI2qUBqtWSk2rX2nl0UW9sPqV0jzS5ZFo3Fj91OqPIBiJ801Gb1z1Ou0IROIIRGOG5nt8FIAwtDEbpeY7XxyLCo8TZ04ZkoN3V3gYht/pqr1C0YRh2CWj0utARzBKSk0BIgY17YEoGq2LgDhMqbGqfgpG42hLGo/L3I7+P+s36fjbWzRKjVuv1Ggv97VS05ugQ++FE2HfZa+r/8/BxfS/2KizMgOlpjusLf4g+gcKanJMVDDzVnocKHc70B2OYV9HEOPqlY6keuOq12UH/MrZgNWYBFlWN+1smu9NG1GNaSOqe/2+ChW9V4htfKJSo+9Rw1AqoILUq6bASCRkxBKqjybTXjW8pFun1FR4HJAk5TvE5yTlIR3LggynXYIzRyqR2EhOr9ToK6z62lPTm0DNk0qpSXFbXyP2qWH7RLnbAafdJig15kENUwWjcdm0qzzRN1D6KceIRmFJkjDMxCzMPB6SpKgufKJuJG7oKCwetNmXKhulptTR5+A9OqUmGpf55mIe1FBX4UKDpVkZmVZAWRmFbTaJN+Rj38P+NgkDat+YXB6cxYne6eZLFXL1k48rNca9jZ2o5COoUfvUqBWWTB1jSo3V/CdxbIf+b5roO+jomGMiybQSOxMz61XDPR4OxfimTtQ1moGddokbWoPR7I3CpY5V+kkMdni5t27DzGao5Y+e/gTX/mMN9aToB8Ix7QEgU08NO4iYdYxlB/+9SX9bPoIa1uE3XY+abMik+olR3weeGk36qRcVlmx6uNkah1Ype+iQKo/htr5G7FPDGkGyz7yxVlVqzPYFvxDUMFsB0fdQ+inHiM33APBRCQc71flPfPiiS1uZFBTLtpMbhCRJ8CQ9N4xctzovZgxBDR+ToF7PRyjo7ss2y3RdQUPROP723i4AwA2nHYZRdWW9WzSRkoguqGnLMP2kNt8zdoyt8jqxG0FBqclf+ilXfhpAbU0AGIMaMeAodzv6xGirFjTYepVeOXvaUCRkGScdVm+47dgxtXj40lmYPLSyx8/fU3j6KRI3KDVMhQ9G42j1Rwzl4pqgJhYHkHknY6Ln0NExx+gnaVcnOwaLg9BY+knv+Nekn8QumrrNKBtPTamjV63YZyn2tGgParsNM8bWK8HJ1kP+lK8hHlR3WUjNRO4wpJ8y9tRYD6pkByLVU9P/53Me3UlMLtBWP2mfV3yPfeGnAVJXLWWDx2nHBTMb0VBpVGMkScJJh9X3idKUDvZ/FRI8NWxyutthTzkDihmFAaP6SPQdFNTkGL1SU5P8ArQH1Y1ZLTFW7sPk6KDYi0ZIlegnbFP6SUWfgzfrPsoCSn1wOGaQEtRsb+5O+Rpi+oO1nCf6DoNSk+GohG4LTw2gHvz3FUT6qW+CGl8KpSbbpnOZctjgChw7phZfnzWyT54/33hEo3BAq9QASGkWNio1RH9A6accIlZtuLhSkwxqRKXGIv0U0Cg11qWSlH5SEfP4zHjNcDvt6ArHLNNPLKjZ1RpALJ6Aw6IiRfy/szIFErlDH9Rk66kxV2oUpeJAJwtq8pd+8vaRp0avlojBU18pNS6HDY9d/oU+ee5CgJ00BSNxrviK5uwRNV6s2tlm2qtGG9SQUtNf0NExh4iyOUt9sM1UnDasnxitpp+MfWoA41gEUmpU9MqM2HuED7vkc6G0n9uwKi/cDhuicTmlr0ZMf5BS0/f0xFMTT8hqUJNCqYknTzryWf3ky6G3haVkKj0O2HWeFm1Q0/+pm1LArKRbq9QkK6BMgppuCmryAik1OSSqCWp0Sk3QqNR4dHJ0MBrn02C1nhr1d7tNslQUBiLiZ6P3KrDbePpJ50Wy2SSMGVSGDQe6sL3Zj9GDzA3AYknxTlJq+pxIXCvVZ6LUsCGVQOr0EyMfnprpI6vhctgwa0wGnQQzZHi1F7edMxlDTSqDvE7RU0NBTU8Qm++xfaTaq6peKdNPEap+ygcU1OQQ8QzTxT01ZkZh81EIgYj50ErxYNzfrd0LnVQD9VgKTz/BW2RsvRLUbGv242SL12jTpZ9kWe73brQDCXZWyxpXtgeiaT9z5qdx2W2mRnpDUJMHpebYsXX45Men59zof8nsMabXiym2vhiRMBAQB1pKMCo1rGXHgQ7jKBytUZg8Nf0FHSFzCBt94LBJvLxR9dREkEhK30Fd+klUasyGVopqhNnAt4GMJvgzmIaZUmPuqQFUX822Q9ZmYTH90R2OZezxIHoGOzloSFaWROIJ+NMMtUyVegLMlJr8VBD2Z+WimH6q7yNPTamjKjUJXuwh/i1Ve60beIqeGn1Kleg76AiZQ/SVT4D6BUjIQHdSjtR7akw7CluUdJOfRotYGaZXYvRKjXlQo4yu2N5sXdYtqmwAlXX3NewAUOV18sA0XVdhtUdNhkFNiQ54FfG6KP3UW8z61FQLRmHWJ6jTZGglGYXzAx0hc0hYGJHA8DjVKdysJDCkq37SpJ/SVD9R5ZOWVOkndkBkY4TMemmwXjWpghq9MkNBTd8SEean1SbTt+nUsa6Q+dwnhj6oKdWp9SKiIZmCmp4h9qlpNynprkwqg93hGGK6/krpjMKRWELjwyRyAx0hc4iZUgOokT1LY7Dme6pRWOhTEzXpUyOmn6jxnoZsmhSazZUZm0w/7e8IIRAxnm0Bavqqtkw5wFIFVN8izk+rSX7m6YZaphqRABiDmlz2iilUyj0O+Fx2uB02nsojsoOfkAajPDARS7orhIGiYhAjy3LKPjWxeAKn//pNnLP0bRq9kmMoqMkh+m7CDLahskhf76lhpcZW6Sc3GYUtyUSpsbodUDo+swaJVmoNMwofOaIKACk1fY34PWKBZLr0U6rGe8DATD857TY8fOks/OXSWTmdNzWQYCeXrP+YTQLKhc/S5bDxfaZLSEGFogkIg+aNvZcCEexoCWDDgS5+PCByAx0hc4iq1GirNPRl3UFdR2FWehmIxNKmn8gorEXTpyadUmNxdj62PrWvhh1Qj2ysBgDsIqWmTxHTuGzMSFsgdVfhVI33ACXYEYunBkJQAwDHjK7FsWPr8r2MokV/IlTldRpmXFUm1ZoOwSwsqjaAMf0klngH0pjgieygI2QOiVikn9SybuXgqPfUMCm8I6h+EazTT/RfJqLpU5NGqbGaIqxWQBmDmmg8ga7kBsWCmp2tqWdFEb2Dp5/sNtSy1G2mRmELpcZmk1AhBDL56ChMFB/6EyW94geIZuEUQY2uT01IUGeCFNTkFDpC5pCIiVEYMI5K0HtqvDyoUTdu8QDs1RiFaTMW0aSf9NVPFhO89agzoIzBCvs/kyRg6nAl/XSwM6zZlIjcwo3CPfDUmE3oZoheiIFgFCZ6j9Nu0yjvVT5jaTxLeXYKJ6V+g1Kj3S9CpNT0GRTU5BDWp0av1KijElj1k/IHrR+TwB4vSdoUFpV0W+NJMSNLPwjUzCgMAOOSFVDbTIIaZu6u8jpRV+biZ/s0A6rvENNPmXpqWPWTlacGUM+yJan3U6WJgYO4r5gqNcn0U1cqpUaXfgoJQY5VgQLRM+gImUOiQimqiH5St9EobJztJHZPpfSTNanSTwalxuJAxnrVbDvUbahEYAfTWp8LkiRhZJ3SFp0qoPoONf1k56nbdCXd6aqfAPWAVOZyUEdoImPEfaM6ZfrJWqnRG4Up/dR30BEyh2SafrLy1DCMpcjUp8YKtyb9pP1s9AGgVVAzqs4HSVJ8GS26gyczqLL/w5G1SlBDFVC954PtrbjnPxsNvTo0Jd0mY0bMSNd8D1CDmoFQzk3kDvGk01ypYemnVEqNdfopXbdsIjvoCJlDIhbVT/pJ3frqJ72BVX8wFoMc6lOjRfys0ik1+ssMj9OO4ckZLnpfDUs/sYMrU2qsgppEQsZ/Nx9Kmy4hgLtf2oDfvb4F721r0VzPBloqnhrlIJK5pyZVUONKex+C0KNRanyZGYX9YW2gYkg/RSn91FdQUJND0io1QXOjsM0mpZzvROkna5RUnfJ7Ok9NKh+F1QwoFtSw0uJRtcr9draYV0C9s7UZF//pA9z27KcZvoOBCzuzFQ2WgHWfmlRNyrrTVD8BQvqJghoiC9xpPDUs5dmVIv1E1U/9Bx0hc4hVR2G9hK731ADQNMdKlX6ioEaLJEn8M9F7k8TPzSYZFTQR1llYbxZm/2e1ZZmln9j1+zuCGb+HgQo7e9U3HxNLutl3J5aQeWm9GeyAUpGq+onST0QP8AonlamMwmbpJ3aCG4nrjcJU/dRXFM0RcsmSJTjmmGNQUVGBhoYGzJ8/Hxs3bsz3sjRYGYX1k7r1nhpAG+DoAxcKalLDPp9UaTyv057SHMob8Ol61TCDKldqkumn3W1BPnVdhB1cQ7ozM8II+x7oy+PFkm6P086DkFQpvUyMwvUVyqgApv4QRCZ401U/maaflL/HuuTfmt5TExaVGmoPkVOK5gj55ptvYtGiRXjvvfewYsUKRKNRnH766fD7C6cRmlX6SZzU3RGM8tJtr8bkmiqoEVNTdJaphwUzqZQaqx41jDGWSo3WUzO0ygOHTUIklsDBrpDheVhZp34TI4xYBjW671FNmq7CiYSsempSBDVnThmCa0+dgOvmHta7hRMDCnHvqDbpU1Np1qcm6ZNhf7up0k/kqcktRZNcfumllzSXH3roITQ0NGDVqlX44he/mKdVaYlY9Klhk7qD0TgOdIY01zN8LmszsIdmP6VkcJUHBzpDGFzp0VxvNT/LDBbU7GzxI56QYU+2Qm/TpZ8cdhuG13ixsyWAnS0BDK3yap6HlJrMYeknfVATjmkVz5oyJ/a2By2VGr9wUEhlAi5zO3D9aRTQENmRrk8NG2rZFRbTT8rfdF05U2r0QQ2ln/qKoglq9HR0dAAAamtrLe8TDocRDof55c7Ozj5dk5WnBlBSUMGOOPdaSJL1hGmjUZhmP6Vi6dePxvYWP8Y3lGuuz0apGV7thcthQySWwN62IK9yatOlnwDFV7OzJYBdLQEcp5urowY1tFGlQpZlIaixLukGkLZXDVNpnHaJ0rNEzkmXfqryWncUZukn6lPTfxTlDpBIJHDddddh9uzZmDJliuX9lixZgqqqKv7T2NjYp+uySj8B6pdhf4ei1HgcWo+HL8P0Eyk1RkbW+XDSYfWG690pGvPpsdkkjKlT1JqtzWoFlL6kG1B9NWZmYZZ+oqAmNeKZq8EoHNd+j3gFlEVZd7fQo4aa6hG5Jm1Jt9BRmPnsWKBdW6b4uAx9ajQdhWmvyCVFeYRctGgR1q9fj3/84x8p77d48WJ0dHTwn927d/fpulSjsHFjZV+GA8mgRq8caI3CKaqfSKnJGO0IhfSf29jkuARmFo4nZD55l/VLAYARNUpQs7fdWOHEuoqGYpR+SoXoMcjUU2Ol1HRmUM5NED2F7dXMuK6nUvBMslSonwc1ym2Ufuo/im4XuOqqq/Dcc8/hrbfewogRI1Le1+12w+1299PKUis1bGNmSo1eOUhlFM7GG0KoaCedp//c9IMtO4NRsAKnaq+q1LCxFx1Bo3GVpZ8isQQSCRk2GykHZohnqlbpJ7c9Q6UmnL6cmyB6Cts7zEYkAMr+7LRLiMZldIViqPA4haCGKTUp0k9RMgrnkh6d9re3t+PBBx/E4sWL0draCgBYvXo19u7dm9PFiciyjKuuugpPPfUUXnvtNYwZM6bPXqunRNJ4agBVqdErB5r0k+42sRcLpZ8yJ9WwSzPUCigl/cQOouVuhyZQZalE86BGvU6/kREqKZWauF6pUT7vNr959VMmjfcIoqewvcPMTwMo+zPvVZP8/jOjcK2lp0YYkxAmpSaXZL0LfPzxx5g7dy6qqqqwY8cOXHbZZaitrcWTTz6JXbt24S9/+UtfrBOLFi3Co48+imeeeQYVFRU4cOAAAKCqqgperzfNo/sHqyndgNqinRmFs0k/AcoXKxxLUPopC7Lx1ADGXjX6uU8MtoGlUmoA5WCdzqA8UNEqNWnST8kDQ2sgglA0jmfW7sVHO9pww+mHYWiVF93JqpMK6hRM9AFs7zDz0zAqvU60+CPcLMyNwuUWfWpiZBTuK7I+Qt5www1YuHAhNm/eDI9HLaE966yz8NZbb+V0cSLLli1DR0cH5syZg6FDh/Kfxx57rM9eM1siMXVmjR52tmmdfhI7Chsfz5QdSj9ljvhZZRTUJJWafR0hBCNxdUK3rlkbb7alC2pkWdYMsiOlxhoxkAnFUgc1tcnU7ef7O3HC3a/jpn99gidW7cFvX90MQBhmSUoN0QewqsqJQyos71PJRyVEEU/I3PzObAfRuIy40KxT06eG0k85Jetd4MMPP8T9999vuH748OFcPekLUs19KRSYUmOWImJRfkA394mRqk8NAIyrL0dzdwSNtYWhShUDdpvEc92ZGIVrylyo9jnRHohie7PfMPeJYZV+CkbjlhsXoUVT/RSxCGrsWqWmKxRDF2Ko8jrREYzi5U8P4mfz5YyGWRJET5k1phb//f7JGFrlsbxPhZB+Evsm1QknRJFYgiu3YvqJlJrckvUu4Ha7Tfu9bNq0CfX1xrLagQTvU+MwmkOrvNoDoz6o8aapcHpwwUy0BaKGZm9EajwOO6LxGDwZpoHGDirD6l3t2N7s53OfanSyc5VPrWgIReP8/1JMPQFGBYJQ0Sg1OqNwWOepGVtfhsOHVsJuA759whicOWUojlvyKlr8EXywvVWd++QhozDRNzQmZ75ZUSn0qvELfZPEsR3hWFwIaqiku6/IOv107rnn4qc//SmiUWXDlyQJu3btwk033YSvfvWrOV9gMaF2QjUeQPX52GyqnwBl4OXwagposoUFiPq5UFaMGZT01TR3o9WkRw0AlLscfDK4mIISTcIAdRVOhfjZiMGfLMuG9JPbYceL156I564+EV8+egQ8TjvmHj4YAPCfTw9wo3CquU8E0ZeIQy3Z32OZ2wGH3QZWACmahcW/+WA0XhSZiGIh66Dml7/8Jbq7u9HQ0IBgMIiTTjoJ48ePR0VFBe64446+WGPRoHYUNio1+gOjIahxZlepQ2SG22IulBWsV822Q37D3CeGzWasdlB+1yk1lH6yRDRKhoQzVZbCBQC3yckB48wpQwAAL60/wP8PKP1E5Avms+sKx3g6tCzpk2R7kJhyFYN6WaYToFyS9S5QVVWFFStW4O2338bHH3+M7u5uTJ8+HXPnzu2L9RUVqfrUGJQaVypPDVU45Qqm1GRiFAZUs/C2Zj+GJGdJiY33GMzX0aFRaiioyRStUqP+zsq5AfPvEWP2+EEodztwoDOE97crbSUoqCHyBau86wxGeYk2+3t0O20IRuPaQF63NwQiMaqUzBE93gVOOOEEnHDCCblcS9GjdhS2HpPAMHhq0hiFiZ7B0k6ZGIUBYAxXaroNHW1FzMzClH7KHK2nRv1dlOhTBTUepx0nT2rAv9ft452GqfqJyBe8IjIUVZUat7L3sJNUcT/QT+0OROLQTpEjekpGu8Bvf/vbjJ/wmmuu6fFiih3ep8a0JFud1A2kTj+RUpM7WDCTaUpvdF0ZJElJJW1L9qsxC2qYMTCVUqPvTUGo6Gc/ybIMSZJ4UGO3SXxSuhVnThmCf6/bxy9TnxoiX5gZhcvc2vQTUyHjCZn/bpOU8Qr6+WdEz8loF/j1r3+tuXzo0CEEAgFUV1cDUDoM+3w+NDQ0DOigRl+KqodN6gbMOgoLfWqowV7OOGH8IGxp6saRI6ozur/HacewKi/2tgfR3K1MeDdrulXFe9WogYxRqaGNygrxs5FlZcN3O+xpv0MicybWw+2w8QCJqp+IfCEOtWQl3Sz9xBRHps6IJzs1Phda/BEeCBG9J6Oj5/bt2/nPHXfcgaOOOgqff/45Wltb0drais8//xzTp0/H7bff3tfrLWhSjUkAtCmobDsKEz3jhtMnYs2tp2N00iuTCcwszNA33wOs0k96pcaYfuoIRDW9bAYqYV3AF4oon1Ukbt3AUo/P5dBMZ6f0E5Ev1D41glGYKzXJoCYZzIhpKHbCRL1qckfWksAtt9yCpUuXYuLEify6iRMn4te//jV+9KMf5XRxxUY0bm0UBrRn/Kk9NaTU5JJ0aQw9Y3QBkHn6KX1Qo1dq9rYHccwdr+Dqv6/Oaj2liGHAX3LDD6cw25tx5tQh/HcyChP5Qk0/RbnqUm4IapS/bZZqctlt/D7UqyZ3ZL0L7N+/H7GYUSqLx+M4ePBgThZVrKSTzsWDo95Tk2qgJdG/jBWCGrfDZlqVYDb/yRjUaA/cmw92IRJPYN3ujlwutyjRB3zscjbpJwA49fDBqPQ44LTbLAcOEkRfI7Z4YNVPqlE46alJ/m2zv3W3U91bApSqzhlZHz1PPfVUXH755Vi9Wj3bXLVqFa688soBX9adqqMwoFVq9EGNh9JPBcOY5GBLwFylAURPjbH6Sa120JdtxjX3G8joA76gLqjJVK2s9Djx7FUn4MnvHp+xukMQuYYpt9G4zL14ZXpPjS6o8Tjt3EsZjJCnJldkvQv8+c9/xpAhQzBz5ky43W643W7MmjULgwcPxoMPPtgXaywKEgk55ewnQDsqQX/2b7dJqK9ww2GTDG35if5FVGpqTPw0QGpPzaByNwDjgZsHNeEYEgPcV6OvDGOfVSRNCteM0YPKMKouc88UQeSaMpeddw5mQ4uN6Setp8bjtHGFntJPuSPr9FN9fT1eeOEFbNq0CRs2bAAATJo0CYcddljOF1dMRBPqAcyspBvQzhAy65vy0CXHoCMYNQxQJPqXYdVeuBw2RGIJywDTNKgJK7/XV7ixtz1omP3EzsZkGeiOxLhkPRDRB3yG9BOpLkQRIUkSKjxKQ8797UEAQkfhpArPq5+YUuOwU1DTB/TYWXfYYYcN+EBGRGzvnqqkm2HWN+WIYVW5XxiRNXabhNF1Pmw62G2ZfuJt0UNiSbfye30FU2rM00+AkrYa0EGNPuDroaeGIAqFSq8DHcEoDnZp0096ozD729emnyioyRVZBzWXXnppytv//Oc/93gxxYzYCdW6pNvaKEwUFmMGlSlBjcmIBCB1+okFNfquoX5h49Kbigca+s+Gnb32JP1EEIWAcpIS5C0b2IBV9resGoXV9JOXlJqck3VQ09bWprkcjUaxfv16tLe345RTTsnZwooNZhJO1QlVYxSmOR8FzcxRtfjPpwdx2OAK09tZUNMdjiEWT8Buk7gBuD7pqdH7RkQzoGgwHojolZoQb0xGQQ1RnOinxFv3qRGUmuTJbTA6sE9ycknWQc1TTz1luC6RSODKK6/EuHHjcrKoYiQT2TxVSTdRWFx6whiceNggHNZgHtRUChtYZygGn8vOU5Bq+sncKMweM5Bhnw3zLlH6iSh29Onkcl1Jd1in1LgddlJq+oCc7Bw2mw033HCDYZzCQELtJmzd6C2dp4YoHOw2CZOGVMJmobo57DaUJTekzmAUnUmVRpLUDsR6T01Q56kZyLCzVmbEJqMwUexU6vokpVdqbNxTw3rbEL0nZy04t27datqUb6CQrpswoKQljh9XB5/LQV2DS4AqrxP+SBwdwSjisqLSlLsdXIXTp1gCGk/NAA9qkmerVV4nDnaGe1XSTRCFgF6p0fepiZgahSn9lGuyDmpuuOEGzWVZlrF//348//zzWLBgQc4WVmxkIpvbbBIevey4/loS0cdUep3Y1xFCRzAKVvtW6XHyjtD69JNf9NQM8PQTO2utTprne9p8jyAKBTYqgcFLug3N99IbhWPxBGIJmRT9HpB1ULNmzRrNZZvNhvr6evzyl79MWxlVyqjdhGkzHiiIFVBSMktV4XHwjYjST9awjb0qmX4Kk6eGKHLEKfFep50XjGTSp0Zf0n3B/e9iX3sQb/7fyRTYZEnWQc3rr7/eF+soeiIx5VzdqpybKD1YDr0zFIUjuYGVux3wOFhQk8ooPNCDGqbU6Dw1lH4iihSxeKBMGK6asvrJRKkJx+JYs6sdgNKdWD9gl0hN1jvHKaecgvb2dsP1nZ2dA7qkm2/GFNQMGESlhvWdUZSa5CamV2qioqdm4KafmLQOqOZ5Q/UTBTVEkSEahVnlE6AGNewYoR2TYJzS3dId4b9TU77syVqpeeONNxCJRAzXh0Ih/Pe//83JooqRaIzSTwMNMahhwWyFx8nl4nBMr9SInpqBq9SInwsbCaLvU0NDXYliQzQKmyo10RRGYWFvYAMxATIQ94SMg5qPP/6Y//7ZZ5/hwIED/HI8HsdLL72E4cOH53Z1RQTz1LhJqRkwiJO6WcpJ9NRE4gnEEzLPrQfCoqdm4G5WoteoUp9+IqWGKFIqLNNP+j41yt+62yn0qYnGIcsyJEnSBDXUvyZ7Mg5qjjrqKEiSBEmSTNNMXq8XS5cuzeniignep8Zh3aeGKC1YDr0zGIPXydJPTs2w0nAsDp/LAVmWEYiSpwYQugYLvX6Cek8NnRwQRUaVJv2UylOTTD851PSTLCvfC4/TjuYuNRNCQU32ZBzUbN++HbIsY+zYsfjggw9QX1/Pb3O5XGhoaIDdPnAlY3aGSUbhgQOr3OkIRrmMXOFxaFInoWgCPpeq2jAGsqdGPVO1qak61qcmufGTUkMUG5bpJ6e+pFv5G/e67JrO8oFIHB6nHYfE9BMFNVmTcVAzatQoAMpIBMIInWEOPERPDTszq/Q4YLdJcNolROMy38D0m1NnMMrl5oGG2CaeqVpkFCaKnXIh/SQahV3Jk321+R5TapSyb7fDhnAsAX84htoyl9YoHKWgJlsyCmqeffZZnHnmmXA6nXj22WdT3vfcc8/NycKKDTIKDzzEoIY13mK9KjwOO6LxGA9qDM21EjKC0TiXn0uVREJGKKZ9n2FulLQZevqwkwNqvkcUG3abhHK3A93hGG+8BxiVmrBQ0g0APpcdYWH+GXlqekdGO+r8+fNx4MABNDQ0YP78+Zb3kyQJ8fjA/E9gwwxJqRk4MLm5MxRFV0j5nZkF3U47usIxrkqwyqdKjwP+SBzxhIzOYKzkg5pvP/whVu1sw1vfP9lQ6eRx2tWgJkbN94jip9KTDGpMq5+Ms58AwOdyoC0Q5QGMpvopMnDT1D0lo50jkUigoaGB/271M1ADGoDSTwMRsfqJdQhmaSi2YbGDNduwytwObjAeCPOfPtzRhs5QDFsPdfPr2Gfidth41Vgwwjw1lH4iihdWzVeesvpJDeoBCKMSlACGlJreQTtHjuBGYap+GjCwDSwhK50/ASH9pDPAss3J67JrOhGXMpFYAt1hZaMWjdFhYVNnGzo7iw1TUEMUMUy9FZUa9rccS8iIJ9OxgKjUaEclNJOnpldkpH3/9re/zfgJr7nmmh4vppjhU7oHcAXYQMPjtHOTHzsYs/STXqlhG5bPZYcEJfAt9V417QF1c9YENRpPjfZzovQTUcwc2ViFj3a24ohhlfw60R8WiSXU6j+H6qkBlBOfWDyBtgB1FO4NGQU1v/71rzN6MkmSBmxQQ0rNwKTK60RTlyoXVwpGYUBVIJhS43M64LAng5oSV2paLYIacVNnn1M0LiMWT5BSQxQ1PzjrcFx18gTe7gHQBjWhaNyQfmK+umAkjtZABLLa+YHSTz0go6Bm+/btfb2OoidKnpoBSaUuqCnnSo12qKU/mS8Xe1N0lnivmla/GNSoARwLXDxOG08/AUqpKw20JIoZSZI0AQ0AOOw22G0S4gmZp2MBVc0VPTVi4z3lOgpqsqVXO4csy5DFsLIfuO+++zB69Gh4PB4ce+yx+OCDD/r19a0go/DAROwiWuay85EIPK2i61NT5rbz8m9mLi5V2gPq+xM3c1794bAbzmIjMSrpJkoPdlzoEL7zXKlxqqMSRJMwoB0pQmRGj3aOP/3pT5gyZQo8Hg88Hg+mTJmCBx98MNdrM/DYY4/hhhtuwG233YbVq1fjyCOPxLx589DU1NTnr52OSEwJ7qhPzcBCDGoqPKLkrO2/wo3CToemFDyfPPDWVnxhyavY3Rrok+fXKjViUJMMXJw2SJLEA5hgJC54asibRpQOrFcNC2qUBp1Go7A+qAlQSXfWZH0EvvXWW3HttdfinHPOwRNPPIEnnngC55xzDq6//nrceuutfbFGzq9+9StcdtlluOSSSzB58mT84Q9/gM/nw5///Oc+fd1MoPTTwEQb1BgbbrHuoazfhE+sfsqzUfjlTw9if0cIq3a29cnztwlBTacm/aQ1SvIKqFic0k9EScICdxbUeIS/b2/SU+MPx3k34boypacTpZ+yJ+vOX8uWLcMf//hHXHjhhfy6c889F9OmTcPVV1+Nn/70pzldICMSiWDVqlVYvHgxv85ms2Hu3Ll49913TR8TDocRDquRb2dnZ5+sDRCNwrQZDyQqxdbowu/6TrkBofqJBT/5Vmr0s2hyjbVRWGuUVMzCUfjDcT4fi4IaopRgATwPaoSZT1ypica4UtNY60OLP0Il3T0g650jGo1i5syZhutnzJiBWKzvzjybm5sRj8cxePBgzfWDBw/GgQMHTB+zZMkSVFVV8Z/GxsY+W5+q1FD100DCKv3k0TXc8ot9apL3y/dQy5Cuw2muET01olFYrX5Sth/mPxKDPApqiFLCpVdqTIKaQCTOh1k21voAUEl3T8h657j44ouxbNkyw/UPPPAALrroopwsKlcsXrwYHR0d/Gf37t199lokmw9MKi3ST0ajsBLAlLkcQvqpQJSaWN8MqRU9NaJRWK1+smv+FdNxlMYlSgl9+omlpwGx+inOG+811ngBUFDTE3o0eOZPf/oTXn75ZRx33HEAgPfffx+7du3Ct771Ldxwww38fr/61a9ys0oAgwYNgt1ux8GDBzXXHzx4EEOGDDF9jNvthtvtztkaUsHTT7QZDyhEpabSNP1k0lG4YNJPfavUtKXpU8MCP/ZZiZUhTlI8iRLC6KkxST9F4vxEYGRSqQlE45BlGZJE34dMyTqoWb9+PaZPnw4A2Lp1KwAl4Bg0aBDWr1/P75fr/wSXy4UZM2bg1Vdf5UM1E4kEXn31VVx11VU5fa2ewNJPFNQMLCqt0k9sMi9TaqKip6YwjMIs4OqrvL1VUBPmZdtJozDv26Ns+C6HjTZxoqQwemrU4wRrvheIxNDiV9JPLKiJJ2RE4gn+eCI9WQc1r7/+el+sIyNuuOEGLFiwADNnzsSsWbNw7733wu/345JLLsnbmhiUfhqYaDw1bhOlJqmG+MNi9VNhDLRkSg2bxZRr2vxaTw074zQqNTppnk4MiBKDpZs603hqWPUT89QAQChCQU029Cj9lC/+53/+B4cOHcKtt96KAwcO4KijjsJLL71kMA/ng2iyTw15AQYWliXdDuap0aaffIKnJpycAyNucP2FLMt8bX2RfgrH4hofTTQuIxxLwOO0awZaiv+yDZ9ODIhSgx0XUgU1+ztCiCWr/wZXeuC0S4jGZQSiMVTBCSIzsg5qQqEQli5ditdffx1NTU1IJLRneatXr87Z4sy46qqrCiLdpCdKSs2AxLL6SVfSLaafyl0OSBIgy0paJh9BDVMWxTXmElb5ZJMAGdr3qvapSbaJ142NoO8QUWq4ndbpJ6/Tobmt0uOAy2GDx2lHNB6jXjVZknVQ8+1vfxsvv/wyzj//fMyaNYty30nCZBQekFhVP1l2FHbZYbNJKHc70BWKoTMURX1FejP74x/thl2S8NUZI3Ky7nBMDGpyn35ifpoanwuRWAJd4Ri6ku9V36dGv+FTUEOUGpkYhRmDkvuBz2VHVyhGFVBZknVQ89xzz+GFF17A7Nmz+2I9RYtqFKYgbyDB5j3FE7Ku+Z42/RQU0k+AMs27KxTLqFeNPxzDzf/6GDZJwtnThuZE2RHVmb4wCrMqjpoyFwLhWDKoUd5rKGbRp4YFNXRiQJQY7G+dqZFuk/QTY1A5C2ocAMKk1GRJ1rvH8OHDUVFR0RdrKWpYUEOD+AYWkiShxqe0NK/2uvj1LPAIx5SSTL8wJgFAVr1q2oNRJGQgppvy2xtEc3BfpJ+YSbjW5+JpORbU6D01ZtVPBFFKsL9p1jHbY9KnhlGfDGrY94K6CmdH1rvHL3/5S9x0003YuXNnX6ynaKE+NQOXm8+chEtmj8akIWqwL/apCccSYMPseVCTRa8aMfDJlRTNfC1A3zTfYyMSqn1OnpZj1V5MqdH3qSGjMFGq6KuXtEZhbcJkULlycuTl/WtoqGU2ZJ1+mjlzJkKhEMaOHQufzwenU+vKbm1tzdniioloPDmlm4KaAcf5M0bgfJ3XhfepicU18jHbwLLpVSOmqPw52uBEH024L4zCyfRTbZmLm5K7kiqTOiaBVT+x9FPSKEzfIaLE0Cv4oqfGbpPgctj4iXFdueqpAWioZbZkHdRceOGF2Lt3L+68804MHjyYjMJQymOpTw0h4nGoSk0golb12G3K9yWbXjXifXK1wWmNwn3gqQmonho296orFIMsy2rzPae2+om+Q0SpIo5FALTpJ0AJYFhQM0iXfqKgJjuyDmpWrlyJd999F0ceeWRfrKcoYSoNQEoNoSCWdAeFCd0MNtQyk/STqNQEwjkKavrYKNzGjMI+J6/46ApFEYmrqTh99RODfGlEqaFXH/U+Gp/TjnYo3xOWfmL7RV+NMSlVst49Jk2ahGAw2BdrKVqiQs8P2pAJQP07iCVkHrj4hIO3ahROn04SA59cpZ/6vqRbWXONzyV4amKa11Krn7QbPCk1RKmhD9w9Oo+NT+hGzkq6vZR+6hFZ7x533XUXvve97+GNN95AS0sLOjs7NT8DkYhwgCClhgC0B2pWCSRuXNkYhUWlpk+Mwn2h1ARUTw0bH9EdivHXlST17NWrD2roO0SUGPqTXX06SlRx1eonNhOKgppsyDr9dMYZZwAATj31VM31bK5LPD7w/gOYUmOTwD0TxMBG3MSYv8Qs/ZRJn5q+UGo0RuFYAomEDFsO/3bFPjW8pDscVcu5HXbux9P7C0ipIUoNg1FYF8iLgX2dLv2UrvrJH47B57KTvzVJTgdafvLJJ71aTLFCBkdCj02oaGD+Eq8m/ZRUajLoU9PXSo1yOWHI8/cG1VOjTz8lK5+EQIbST0Spky6oYQGMz2XnFZK8pDuFkrqlqQtn/eZt/M8xjbh9/pRcLrloyTqoOemkkzSXu7q68Pe//x0PPvggVq1aVZBzmfoa6lFDmOFJBjWplJps+9T4c2QU1vtoQtF4zoKacCzOK57E5nudoRj38oieAmP6iSYSE6WFoU+NQ59+Ug7FrPIJyKz6ae3uDkTiCazd3Z6jlRY/PT4Kv/XWW1iwYAGGDh2Ke+65B6eccgree++9XK6taGDVT+QFIETY2RhTLcQmW9kYhTXVT9FcGYW1G2Uolru0MRtmabdJqPA4NM33mFLj0Sg1lH4iSpu06afkCQWrfALE9JP1d7PVHwaQu7R0KZCVUnPgwAE89NBD+NOf/oTOzk587WtfQzgcxtNPP43Jkyf31RoLHqbU0GZMiLCNq5UZhQUlRN9lNxWaPjU5K+nWKzW5q4BqFcq52fBOQDEKs9cRz1z1Z7H0PSJKDWOfGvP0U52o1GRQ/cT2Fhp6qZLx7nHOOedg4sSJ+Pjjj3Hvvfdi3759WLp0aV+urWiIxCn9RBhhCkRbivSTPxJHLJ46oOgUlZocbV56ZSaXFVBtfESCctYpmqLDMaNSo097UVsEotTQp1T16mSZ25h+YspuKk8NV2pyNBOuFMhYqXnxxRdxzTXX4Morr8SECRP6ck1FR5SMwoQJTIHgRmEh/VQhTPTuCsVQU+aCFdqOwrkfaAmkb8D33rYWlLsdmDK8Ku1zi8MsAfW9BqNxPpBT7NthMArTyQFRYqRTas6ZNgzrdrfjazPVcSt8oGUmSg016ONkvHu8/fbb6OrqwowZM3Dsscfid7/7HZqbm/tybUUDGYUJM9jZWIvfqNQ47DaUubTTqa3Qzn7KbvNq6Q5j/d4Ow/XZKDUdwSgu/tP7uPCB9zJSdNQRCYpCUy4EcM3dym2iGqM3TdLJAVFqpJr9BACTh1Xi0cuOw9Eja/h1PP2UwkfHlJpoXNb0SxvIZLx7HHfccfjjH/+I/fv34/LLL8c//vEPDBs2DIlEAitWrEBXV1dfrrOg4UqNnfoEECrsbIyNCfDp0iwVGfSqicUTmpRTthN7v/vIanxp6dvY3uzXXK9XavSXRZo6Q4jGZXSFY1i9sy3ta7YJwywBJdhnAd6hLmUTFs9UHXYbnMJ3h4IaotTQ+8b0yo0ZmRmFI/x38tUoZL17lJWV4dJLL8Xbb7+NTz75BN/73vdw1113oaGhAeeee25frLHgofQTYYZ+IxOrn4DMetXoA55sS7p3tgQAAHvaAprrwzFjSbcV7cL63tmaXp3Ve2oANYBr7jYGNYD2zJXST0SpISo1kpSZbyzboIYqoBR6tXtMnDgRP//5z7Fnzx78/e9/z9Waio4wpZ8IE8wm8Ypk0qtGH9RkmztnBkK9wVgfxKR6XlaiDQDvbGlJ+5pcqdEENUoAx4IaY9t4IaihkwOixBD/pt0OW0bdf3mfmmgcsiwbbo/GE31SRFDs5GT3sNvtmD9/Pp599tlcPF3RwfrUUFBDiFj1omCwXjVtAeugRh/wZFPlIMsyupNnb/qzPaNSY51+YsoLAHy8p52n06xoZcMsy1IpNfqpxeplCmqIUkPjIdPtC1aw/UKWjd9XQD15YOSqiKDYod0jB1CfGsKMdErN4EqlfPNgZ8jyOZhSwzwn2eTNA5E42AmeXppmSg0b95TSKCwEXQkZeH9barWmnQ+zdPLr2FBL7qkxdFglpYYoXRx2G58LqP/bt0JMV5upMK0BfVBDSg1AQU1OUI3C9HESKvrNS++pGVrlBQAc6LAOaphS01DhAaAEJ2ZStBmiqmOl1FQl1aJUHYXbdJvnO1tS+2pYnr/aNP2UrH5KUeLqpu8RUYIwtUZ/smOFPTk/DjBXYVq7Sakxg3aPHEBGYcIMq66hjCFVSqCyP0VQw5QapuokLKRoM7rD1vl29hws8EiVfmJG4cOHVgIA3tmaWqlJ5amJJ5SATB/weclTQ5Q4Lh7UZD7bjO0ZZkpqiyH9REoNQEFNTlCNwlTSTajozbD6oGYoD2qCls/BGu8NrvTw6zLdvMRKKUNQk9wkma8nZfVTUqk5c8oQSBKwpanbMmUmDrM089Qw9EqNeJmCGqIUYfuBO4ugJtVQS72CmqsRKsUO7R45IEpjEggT0hmFh2ah1FT7nFy2ztQs3K1JP2kfY0g/ZVD9NKrOh6nJjsJWKShxmGWl0HSPzX9iGEq6SakhShzW4kHfbDIVqeY/tVD6yRTaPXIApZ8IM4xGYe2BfUjSU9MVimkCEBHWw6bC48xoFoxI6vSTcrk6g6CGVWdV+1w4ftwgANal3eIwS7FsVRwLAaRJP9HJAVGCuHuRfjIrEGjVpZ+y7TZeqtDukQN49RNtxoSAXmb26i6Xux38YG9lFmZKTYXbwTe4TJUa8X4BXdDCPDTVPqfmshkdrJme14kTxitBzcqtzaaG5TYe1GhnWVWmST95KP1ElDiuLI3CAOBzWp/IsOonVsFIHYUVaPfIAaxPDW3GhIhHM7RRLekUSeer6QorKkml15lRh1GR7pTVT9krNTU+F2aOroHLYcP+jhC26UYvaO6rG9CpV2r03ZbFgE9/G0GUAj1Rajwp0k+s+olVUVJHYQU6CucA6ihMmCHmzvWpJwZLQVn5ajqDSaXG4+DPkanMLCo14u/xhMwDcWYUtkpphaJxfluVzwmP046Zo5SheytNfDVswF6NT6vM6I3C+rNV8tQQpY7qqcki/cQndZuUdCdV0RE13uR9SKkBKKjJCWQUJswQD9T61BNjWFKpsU4/iZ4adtaWffpJDFrCQk8aZhS2GmjJugeLxt/jxtYBAFbvajfcf+shRb0ZUePTXF+eRqlxa5Qa+h4RpQdLuWaVfkql1ARYUKN818hTo0C7Rw4gozBhhhjU6Mu5GUPSpZ9CRqUm05LuLgujsBjA8D41Fs33WDVTlVc1/k4boVRAfbyn3XB/dh2rkmIYjML6MQlkFCZKHPZ3nU36iVU/6ZVUWZa5f01Vaij9BFBQkxNUozD1qSFUxAO3z22efkpX1s0G1lUKSk1PjMKiNM0CGKddQlmK5l6A2qOmWkgnsYBlW7OfK0kAEIsn8Nn+TuU+I9IFNfqSbuWzctgk2Ey8RwRR7DA1sid9avSppc5gDLFkI0sW1PipTw0ACmpyAqWfCDPEFIvPYiNLNyqhk6efHChzZ2cU1jbfUwMcptS4HXa+wVp5ang5t1cNaurK3Rhe7YUsA5/u6+TXbznUjVA0gXK3A2PqyjTPY6h+cph7akjtJEoV9h3S+81SYZV+YqmnMpedVxrqKxwHKkWxg+zYsQPf/va3MWbMGHi9XowbNw633XYbIpFI+gf3AxGqfiJM0Cg1FumnVEpNOBbnKmCl0Kcm09y5VZ8aptR4nDa+RquS7o6gcY4ToKo1n+zp4Nex348YVmlQW9wOGxzCdYbGhBTUECXOFXPG4eYzJ+Er00dk/BivRcqZGfJry13wJU92AhkquKWOuSZeYGzYsAGJRAL3338/xo8fj/Xr1+Oyyy6D3+/HPffck+/l4StHD8fRjdV8Ng5BADqjcBpPTUcwikAkpqmSYn4aQDHaqiXd2aefwrEE4gkZdpukUWpYMGGVflIb72nPLqeOqMJLnx7Ax3uFoCb5u95PAwCSJKHC4+DPZ5V+Ij8NUaoMr/biipPGZfUYq9lPrX7le1Trc2XttSt1iiKoOeOMM3DGGWfwy2PHjsXGjRuxbNmygghq5h89PN9LIAoQsXTTSqmp8DhR7nagOxzD/o4QxtWX89tYUFPudsBuk3ql1ABKiqnc7eAtCNwOGw8urKqf2nn6SavUMLPwerOgZoQxqAGU98qCGn36yU1KDUEYUGc/ab/LXKkpc3FfHI1JUCjaHaSjowO1tbX5XgZBWOLWpJ+szx+GWpR1qyMSHMnn6HnzPUCVp9lZn9tp50FNJJ7gE7RFmFFY7wOYMkwJXLY3+9ERjCIaT+CzpL/GTKkR3wdgVGrYRO8qb+Z+A4IodaxmP7EJ3bVl7pTzoQYiRaHU6NmyZQuWLl2aVqUJh8MIh8P8cmdnZ4p7E0RucTtskCRAlq2VGkBJQW1u6sa+dm1Zt1jODajPkWnnUH2VFNv0tEqNGniFonGU6aq02i3STzVlLjTWerG7NYhP93ag2udCOJZAhduB0TqTMIMNtXTaJUN35WkjqvDT847AtBHVGb03ghgI+CxKutt4UONEWfKESUwxD2TyqtTcfPPNkCQp5c+GDRs0j9m7dy/OOOMMXHDBBbjssstSPv+SJUtQVVXFfxobG/vy7RCEBkmSeJolVVBjpdSIjfeU58gud64v8WSPY0qNx2nTpMjMfDVtAXOjMABMG14NAPh4bwdPQx0x3GgSZrD3YTYGQZIkfOsLo3FUY3Wqt0QQAwqvhTprptQAlIIC8qzUfO9738PChQtT3mfs2LH893379uHkk0/G8ccfjwceeCDt8y9evBg33HADv9zZ2UmBDdGveJx2hKIJXsVgBh+V0KkPaliPmqRS4848dx6JJRBJthqo8SlelmBUeZyq1Nhhs0lwOWyIxBIIxYy+GtZRWK/UAIp35vlP9uOTPR2oKVNuT6W0sPeRTUdVghjIqJ4avVFYCWrqylxwO5S5cvGEjEAkbhhJMtDIa1BTX1+P+vr6jO67d+9enHzyyZgxYwaWL18Omy39xuh2u+F2u3u7TILoMUypKUuh1FiNSujUKzVsg8ugyZaYehpU7kZbICqkn+KatXlYUJNCqdFP3QaAaUnvzMd721FbpnzPplj4aZT34Ui+Lg2sJIhMYOqsVfqppswFSZLgc9rRFY6RrwZF4qnZu3cv5syZg1GjRuGee+7BoUOH+G1DhgzJ48oIIjXMEGtV0g2oZd16T02nzlPD/C6ZbFzMJOxx2vjj1fRTQrM2j9OOzlDM1IAsjknQc0QygNndGuQBmZVJGFDnP7lJqSGIjLCa96amn5STDZ9bCWoy7TZeyhRFULNixQps2bIFW7ZswYgR2sZFsmys2CCIQoF5VlJXPyW7ChvST3pPTeZGYRbUlLvVpn1BK6WGlXXr5j8FI3GeqjJLP1V5nRhd58OOlgCicRkVHgdG1foM92Ow95HNlGKCGMh4eZ+aBBIJmfvVxPQTwPaXMCk1KJKS7oULF0KWZdMfgihk5kysR12ZK6WCwZSa9kBUo5ZwT42XVT+pwUm6v30/D2rshpJPptTopwbruwq3J7sJO2wSr1zSM1Xw0EwZVpVyblMFeWoIIivEQa+sE3goGuff5Roe1FCvGgbtLgTRhyw+63B8+MO5PHAxo9Lj4J4bcVq32qcmqdQkjcKxhMxNwFYwpabM7TBseEyRYYqJVVfhNr9qEmYTuvVME4K1aRZN9xhDKpXPgPlvCIJIjRjUsECGqTROu6QWEVCvGg4FNQTRx6SbOi1JEg96RLOwofpJ2ODSNeBj5dzaoCaZftIpNW6nKnGLtFvMfRIRuwenMgkDwEmH1eOur0zFLV86POX9CIJQsNkkrmwGdUFNjc/FTzZoVIIKBTUEUQAwX4042LIrrO0o7LDb+BiBdKMSupOPLXc74HVqNzy9UuOxmNTdYTKhW88RwyrBYrYj0zTOc9ht+PqskRhl0ZyPIAgj+oClVWcSVu5D6SdGURiFCaLU4UqNYBbuDDKlRg0qfC47IrFE2qGW3UmlptxtHISpV2o8Duap0aWfeDdha6WmwuPEPRccie5wDCPrrE3CBEH0DK/upMM8qCGlhkFBDUEUAMNMyrr11U8AUOZyoD0QNXQL1uMXPDV6o7DYfA8QKyy0z6mmn1I38/rK9BEpbycIoud4dSqMvpwbEJQaKumm9BNBFAKsqzDz1MiybJj9BGRe1i1WP/EpvlHjmARATUOFdR2FWY8a/TBLgiD6D/0g2zazoMZNRmEGBTUEUQCw+U/MUxOKJhBLTs02C2rSGYW11U/6PjVapUYt6dYpNSnmPhEE0T/oRyWYKTVsqGU6r91AgIIagigAhlYrQc3OFj9C0TgfkWCT1A0LUHPn6TYvValxGORrg1LjNA+U2lJ0EyYIon/QT+pu9YcBqI33NPchozAFNQRRCExoqMDwai/8kTieXbeP+2nK3Q5NSXimm5d5nxpzpYaXdMfMq5/M5j4RBNE/6Cd1s/5RNSZGYVJqKKghiILAbpNw8RdGAQAeXrlDmPukVUl8yc6+6YzC3aZKjfmYBK9Fn5q2QGZGYYIg+g6xJUMoGsfOVj8Ac6NwurT0QICCGoIoEP5nZiPcDhs+3deJNzY0AdD6aQC1AZ++p4wev6akW+upUcckpPHUBNWOwgRB5AdRnf3Bk5/gYGcYtbrRK9nMhSt1KKghiAKhpsyFLx89HACwfOUOAEClV6/UJDevNKWb/gzGJOgHWopBjSzLZBQmiAKAfX//tXovnlyzF3abhN9942iNiqs/cRnIUFBDEAXEguNHAzCOSGBkOuNF9dTYDdUTTKnxGJQaNf0UiMQRjSvVV1TSTRD5g31P9yZ7WC0+cxKOHzdIcx9+skNKDQU1BFFIHD60ErPG1PLLBk8N7xyamVG43O1AWdKHE44lEE/IKTw1aqDE/DQuu00zVI8giP6FncgAwDlHDsO3TxhjeR9SaiioIYiC45KkWgMYlZoynju33rwSCZmrMuKYBEDx4vDqJ/1AS6H6iTXeq0oxoZsgiL5naLXSmHPi4Arc/dWppt9H3qcmTQHBQIDGJBBEgXHa5MEYVuXBvo6QpVKT6oxMlKDL3A64HTZIEiDLSkM9Wckqqeknh7H6qSNI3YQJohA4c8oQ/OGb03Hc2Dr+/dfjFXrZJBKypg3EQIOUGoIoMBx2G246cxLqylw4aWK95rZMjMLsbM1hk5IBjcSrpliPC0A0Civ/ioESL+f2kkmYIPKJ027DGVOGpjTsiw0601VGZsLHe9qxamdrr58nH5BSQxAFyHlHDcd5Rw03XK/vLmqG2HiPSdVelwP+SJwHK5Kk+GUAVbEJm6SfqJybIAofj1NVYwOROPfR9YR4QsZFD76PSCyB1bec1qvnygek1BBEEcE7h6ZQakSTsPq4pFKTDGqYggOYN99rp8Z7BFE0iGpsuiKCdHSHYugKxRCOJdDSHcnF8voVCmoIoogwq3L497p9+ONb2/hlf6qgxs+CGtU8bNanpp1GJBBEUeF1qZ2HewObOweo3rpiorh0JYIY4OhnvAQjcXzv8XWIxBOYM7EeEwZXaHrUMLxcqVE2KeajEX+PJWRE4wk47TZ1mCUpNQRRFJS57WjuzoFSI6jAxRjUkFJDEEUEC1TYxrVmdxsicSVttOFAFwBtN2H+uGQwpKafjEoNoKo1u9sCAIBhVd7cvwmCIHKOvslmT2GNPwEKagiC6GN8yeF20biMSCyBD7arFQqbD2qDGjH9pFdqWOWT/nfmq9nerAzNGzOoLOfvgSCI3FOW4bDbdHQVefqJghqCKCK8YiO9SBzvb1ODmk0HuwEAXSZKjd5TI6ozkiRphlp2haI41BUGAIymoIYgigK1MrJ36SdSagiC6DdcDhucdqVqqSMYxepdbfy2zU3WSg3b8Fr9avWTiFjWvaNZST0NKnehykueGoIoBvikblJqCIIoJphZ+L1tLQjHElxl2dESQDgW55uaJv2UTFuxUm2Pbp4T6yocjCSwrVlRfMYOKu/Dd0EQRC7J1aTuLjIKEwTRn7Azsjc2NQEATjqsHhVuB+IJGdub/Zrme/rHtAaslJpk+ikWx7ZD5KchiGKDKzW9rH4S00+dFNQQBNHXsM3rv5uaAQDHjqnDhMGKqrLpYLeQfjKWdDMjsNtpnn4KReOqSbieghqCKBZyNamb0k8EQfQrTGZmMvGsMbU4bHAFAGDLwa6USg3D49BdFroKU+UTQRQfag8r5fvfEYzitF+9iZ/8+9OsnoeMwgRB9CtigFLhduDwoZWYkAxqNh3sNg1qynTTfY1KTXKopaDUjCOlhiCKBrYvsD41b206hM1N3fj3un1ZPU93kQc11FGYIIoMMViZOboGdpuECQ3J9FNTFxw2pTqqwqRPDcNtodTsbg2gOxyDTQIaa319sn6CIHKPL/l9DyQLBVbtVCojW/0RJBIybMl9IR2k1BAE0a+IAcqsMXUAwNNPO1sCaPUrG1Gq9JNeqWHdSD/b3wkAGFHjMwQ+BEEULnygZbIr+Jpku4eEDLRnEZyIs586Q1EkEnIOV9n3UFBDEEVGmSaoqQUADK50o8KjVEA1dyuN88p6oNR8ngxqxlLqiSCKCj5CJRxDMBLHp/s6+W0tyT0hE0SlRpa1Jd7FAAU1BFFkMEOgx2nD1OFVAJSuwCwFxdA239Nmmj0WnhoyCRNEcSJO6f54TztigsLSkmy6mQnduiCm2Mq6KaghiCKDpZKmj6yBS+g3w1JQDHFKtyH95DC/LCf3wbEU1BBEUVHGjcIxrBI6jQNAS3dmQY0syzyosdvUzuXFRNEFNeFwGEcddRQkScLatWvzvRyC6HeOHVsHn8uOr04fobl+gj6ocYkdhfVBjHmfGsYY6iZMEEWFT1BqVu/UBjWt/szST4FIHPGkwjO0ygOAgpo+5/vf/z6GDRuW72UQRN446bB6rP/xPHx1hjaoOWywGoiUueyaagdDnxpdEKMPeshTQxDFhTr7KYbVu9oBAJOHVgIAmjNUapifxm6TMKSSgpo+58UXX8TLL7+Me+65J99LIYi8YlaeOaFBVWpEk7DZZasxCex3tqERBFEc+NxsTEIcrf4IXA4bvnhYPQCgJUOlhnUTrvA4+DDbYvPUFE2fmoMHD+Kyyy7D008/DZ+P+mcQhB5WAdUVimlMwoASxEiS6pkxDLQULo+uK8u4pwVBEIWBvhhg6vAqnkJqzdAozCqdxKCGlJo+QJZlLFy4EFdccQVmzpyZ8ePC4TA6Ozs1PwRRqkiSxM3CemVGkiTexwJIrdRQ6okgig99CnnGqBrUlrkAZJ9+qnA7UUlBTfbcfPPNkCQp5c+GDRuwdOlSdHV1YfHixVk9/5IlS1BVVcV/Ghsb++idEERhwHw1YuUTwyucyaUyCo8lkzBBFB12m6Q5OZk+sgZ15UpQk7FSk0w/lRexUpPX9NP3vvc9LFy4MOV9xo4di9deew3vvvsu3G635raZM2fioosuwsMPP2z62MWLF+OGG27glzs7OymwIUoaptRUe12G20SzcKr0E/WoIYjipMzlQCiqBDDTR1WjLdldPNPme0ypqaSgpmfU19ejvr4+7f1++9vf4mc/+xm/vG/fPsybNw+PPfYYjj32WMvHud1uQyBEEKXMV6aPwI5mv6EyCtAGNcaBlkJQQ+kngihKvC474AdG1vrQUOGBTVK8ce3BKGLxBBz21MkZNsyywuOkoKYvGTlypOZyebkij48bNw4jRhg3b4IYqFR5nfjJeVNMbxNHJXj0YxKEdBQ13iOI4oT1ppo+shoAUONz8QKBtkAU9RWpT/JLofqpKIzCBEH0nlRKTblH2Qzrylyo9hlTVwRBFD6srHvGqBoAis+mJvl9zqSsuzMkVD/5SKnpN0aPHg1ZLq7JoQSRb3wao7BWqTl8SCUuP2ksnyVFEETx8c1jR8HrtOPsaWqD2royF1r9EbRmUAHFPDXlbko/EQRR4GiNwlqlxmaTsPjMw/t7SQRB5JCvzhhh8NPxsu4MKqC6wybpp1AMsixDkoqjdxWlnwhigCAGNa40hkGCIEqDQeWKj6Y1gwqorpCx+V48IRsmdxcytLMRxADB61SEWYdNSlsFQRBEacCUmpYMlBq1pNsJj9MOV7KAoJhSULSzEcQAgSk1+h41BEGULqwBX2ZBjdp8D0BR+mooqCGIAQIr6dZ3EyYIonSpY0qNkH6SZRm/+M8G/OXdHZr7iuknoDiDGjIKE8QAgZQaghh41CU9NS1C9dPWQ9247/WtcNgkfGPWSJ6OVgdaKsFMMfaqoVM2ghgg+EipIYgBB/PUiPOfPtvfBQCIJWTs7wgBAMKxOCKxBIDiVmpodyOIAQLrU+OioIYgBgyDytmkbjX9tGF/J/99d1sAgJp6AtTOxJXJ4IaCGoIgCo4hVR4AQEOlJ88rIQiiv6grU9JPnaEYV2I2Hujit+9pDQIQG+85YLcpPWmKUakhTw1BDBBmjqrBsoumYwp1DSaIAUOV1wm7TUI8IaMtEMHgSg82CEENU2q6dSZh9liAghqCIAoQSZJw5tSh+V4GQRD9iC05/6m5O4yW7gg8Tjv2tgf57btbWfpJ7SbMqORBTfE036OghiAIgiBKmLqyZFDjDxu6A+9pUwKcTiH9xChGpYY8NQRBEARRwvAGfN0RbDygmITrKxSvjWoUZkqNkz+OghqCIAiCIAoKcVTC50k/zdzDGwAABzvDCEXjXMEx89RQnxqCIAiCIAqCQbwBX5iXcx83to73rtrXHhS6CQtKjY+UGoIgCIIgCgim1DR3h7HpYDcA4PChlWis8QEAdrcFefqp0qL6SZbl/lxyj6GghiAIgiBKGOap+XhPB7rDMbjsNowZVIYRNV4ASgVUVwqjcDwhIxCJ9/OqewYFNQRBEARRwrAGfKw/zfiGcjjtNjTWKkrNnragYZglAHiddjjtSiO+YklBUVBDEARBECUMU2oYk4ZUAICq1LQFDMMsAaW3VbFVQFFQQxAEQRAlTF2ZLqgZyoKapFLTGjBtvgeIDfgoqCEIgiAIIs+w9BNj0pBKAEBjLVNq1PRTuS6oKTalhjoKEwRBEEQJU+l1wGGTEEsoFUxq+klRalr9EUTjyrDLSiH9BBRfUENKDUEQBEGUMJIk8bLu2jIX7yZc5XXyEm4zozC7D1A8DfgoqCEIgiCIEqcu2YBv0pAKSJLEr2cVUIwKUmoIgiAIgihkBiUroJifhsEqoBhinxqAghqCIAiCIAqMycOUYOb4cXWa61lXYQBwO2xwObRhwZAqDwBgc7ITcaFDRmGCIAiCKHG+P28SvjFrJEbq0k1i+kmfegKUGVEAsGpXG0LRODxOe98utJeQUkMQBEEQJY7dJmFUXZnGTwNo00+VHqPOMXZQGYZUehCJJfDRjrY+X2dvoaCGIAiCIAYoolKj71EDKJVTs8cPAgC8vaW539bVUyioIQiCIIgBiqjU6Mu5GbPHKymolVspqCEIgiAIokDxuRx8jEKF2+ipAcCVmk/2dqA9EOm3tfUECmoIgiAIYgAzIpmCslJqBld6ML6hHLIMvLetpT+XljUU1BAEQRDEAIaloMyqnxizk6Xghe6roaCGIAiCIAYws0bXAgAOT07vNoOloFZuKWylhvrUEARBEMQA5ltfGIUzpgzB4EqP5X2OHVsHmwRsa/ZjX3sQw6q9lvfNJ0Wl1Dz//PM49thj4fV6UVNTg/nz5+d7SQRBEARR1EiSlDKgAZRxCdNGVAMA3ingFFTRBDX/+te/cPHFF+OSSy7BunXr8M477+Ab3/hGvpdFEARBEAMCtbS7cFNQRZF+isViuPbaa/GLX/wC3/72t/n1kydPzuOqCIIgCGLgMHv8INz3+la8vaUZsiwbuhMXAkWh1KxevRp79+6FzWbD0UcfjaFDh+LMM8/E+vXr8700giAIghgQTB9ZA7fDhkNdYWxr9ud7OaYURVCzbds2AMCPf/xj/OhHP8Jzzz2HmpoazJkzB62trZaPC4fD6Ozs1PwQBEEQBJE9Hqcdk4YoFVIbD3TleTXm5DWoufnmmyFJUsqfDRs2IJFIAAB++MMf4qtf/SpmzJiB5cuXQ5IkPPHEE5bPv2TJElRVVfGfxsbG/nprBEEQBFFyTBisBDWbDhZmUJNXT833vvc9LFy4MOV9xo4di/379wPQemjcbjfGjh2LXbt2WT528eLFuOGGG/jlzs5OCmwIgiAIooccNrgcALC5qTvPKzEnr0FNfX096uvr095vxowZcLvd2LhxI0444QQAQDQaxY4dOzBq1CjLx7ndbrjd7pytlyAIgiAGMkyp2UxKTc+prKzEFVdcgdtuuw2NjY0YNWoUfvGLXwAALrjggjyvjiAIgiAGBhMaFKVme7Mf0XgCTnthWXOLIqgBgF/84hdwOBy4+OKLEQwGceyxx+K1115DTU1NTl9HlmXEYjHE4/GcPi9B5AK73Q6Hw1GQpZQEQZQ+w6u9KHPZ4Y/EsaPZz5WbQqFoghqn04l77rkH99xzT5+9RiQSwf79+xEIBPrsNQiit/h8PgwdOhQulyvfSyEIYoAhSRLGD67Aut3t2NzUTUFNoZJIJLB9+3bY7XYMGzYMLpeLzoaJgkKWZUQiERw6dAjbt2/HhAkTYLMVlvRLEETpc1hDOdbtbsemg104a+rQfC9HAwU1SSKRCBKJBBobG+Hz+fK9HIIwxev1wul0YufOnYhEIvB4Us9rIQiCyDUTWAXUwcKrgKLTPB105ksUOvQ3ShBEPinkXjW0OxIEQRAEkTGHJYOa7c1+RGKJPK9GCwU1REkyevRo3HvvvXl/jp4wZ84cXHfddf3+ugRBEJkwrMqDcrcDsYSMnS2FNQOKgpoS4MCBA7j22msxfvx4eDweDB48GLNnz8ayZcuKqpKrP4OIQCCAxYsXY9y4cfB4PKivr8dJJ52EZ555ht/nww8/xHe+851+WQ9BEESxIEkSxif71WwSfDUPvLUVP3jqE+xuzd9xh4zCRc62bdswe/ZsVFdX484778TUqVPhdrvxySef4IEHHsDw4cNx7rnn5m19siwjHo/D4SisP7UrrrgC77//PpYuXYrJkyejpaUFK1euREtLC79PJt2uCYIgBiITGsqxNlkBdTaGIhiJ4w9vbkOrP4JZo2vRWJufghtSaoqc7373u3A4HPjoo4/wta99DYcffjjGjh2L8847D88//zzOOeccft/29nb87//+L+rr61FZWYlTTjkF69at47f/+Mc/xlFHHYW//vWvGD16NKqqqvD1r38dXV2qGSyRSGDJkiUYM2YMvF4vjjzySPzzn//kt7/xxhuQJAkvvvgiH2/x9ttvY+vWrTjvvPMwePBglJeX45hjjsErr7zCHzdnzhzs3LkT119/PR9mynj77bdx4oknwuv1orGxEddccw38flXybGpqwjnnnAOv14sxY8bgkUceSfu5Pfvss/jBD36As846C6NHj8aMGTNw9dVX49JLL+X30StHGzZswAknnACPx4PJkyfjlVdegSRJePrppwEAO3bsgCRJePLJJ3HyySfD5/PhyCOPxLvvvsufo6WlBRdeeCGGDx8On8+HqVOn4u9//3va9RIEQRQSzFezuUk5Pvzjw11o9UfQWOvFl6blr8ybghoLZFlGIBLLy48syxmtsaWlBS+//DIWLVqEsrIy0/uIwcEFF1yApqYmvPjii1i1ahWmT5+OU089Fa2trfw+W7duxdNPP43nnnsOzz33HN58803cdddd/PYlS5bgL3/5C/7whz/g008/xfXXX49vfvObePPNNzWve/PNN+Ouu+7C559/jmnTpqG7uxtnnXUWXn31VaxZswZnnHEGzjnnHD6Q9Mknn8SIESPw05/+FPv37+dDTLdu3YozzjgDX/3qV/Hxxx/jsccew9tvv42rrrqKv9bChQuxe/duvP766/jnP/+J3//+92hqakr52Q0ZMgQvvPCCJmBLRTwex/z58+Hz+fD+++/jgQcewA9/+EPT+/7whz/EjTfeiLVr1+Kwww7DhRdeiFgsBgAIhUKYMWMGnn/+eaxfvx7f+c53cPHFF+ODDz7IaB0EQRCFgFjWHYkl8Me3tgEALv/iODjyODqhsHICBUQwGsfkW/+Tl9f+7Kfz4HOl/6/ZsmULZFnGxIkTNdcPGjQIoVAIALBo0SLcfffdePvtt/HBBx+gqamJD/m855578PTTT+Of//wn944kEgk89NBDqKhQovCLL74Yr776Ku644w6Ew2HceeedeOWVV/CFL3wBgDJF/e2338b999+Pk046ia/hpz/9KU477TR+uba2FkceeSS/fPvtt+Opp57Cs88+i6uuugq1tbWw2+2oqKjAkCFD+P2WLFmCiy66iBtnJ0yYgN/+9rc46aSTsGzZMuzatQsvvvgiPvjgAxxzzDEAgD/96U84/PDDU352DzzwAC666CLU1dXhyCOPxAknnIDzzz8fs2fPNr3/ihUrsHXrVrzxxht8fXfccYfmPTJuvPFGnH322QCAn/zkJzjiiCOwZcsWTJo0CcOHD8eNN97I73v11VfjP//5Dx5//HHMmjUr5ZoJgiAKBbEC6p+r9mBfRwj1FW6cP2NEXtdFQU0J8sEHHyCRSOCiiy5COBwGAKxbtw7d3d2oq6vT3DcYDGLr1q388ujRo3lAAwBDhw7lqseWLVsQCAQMB/JIJIKjjz5ac93MmTM1l7u7u/HjH/8Yzz//PPbv349YLIZgMMiVGivWrVuHjz/+WJNSkmWZd4DetGkTHA4HZsyYwW+fNGkSqqurUz7vF7/4RWzbtg3vvfceVq5ciVdffRW/+c1v8JOf/AS33HKL4f4bN25EY2OjJuCyCkKmTZvGfx86VJFhm5qaMGnSJMTjcdx55514/PHHsXfvXkQiEYTDYWr4SBBEUTE0WQHVHY7h7pc2AAD+94Qx8DjteV0XBTUWeJ12fPbTeXl77UwYP348JEnCxo0bNdePHTtWeR6vl1/X3d2NoUOH4o033jA8jxgAOJ1OzW2SJCGRSPDnAIDnn38ew4cP19yPqT8MfTrsxhtvxIoVK3DPPfdg/Pjx8Hq9OP/88xGJRFK+x+7ublx++eW45pprDLeNHDkSmzZtSvn4VDidTpx44ok48cQTcdNNN+FnP/sZfvrTn+Kmm27q1Vwl8TNk6T/2Gf7iF7/Ab37zG9x7772YOnUqysrKcN1116X9HAiCIAoJVgG1dnc7OoJRVHocuOi4UfleFgU1VkiSlFEKKJ/U1dXhtNNOw+9+9ztcffXVlr4aAJg+fToOHDgAh8OB0aNH9+j1Jk+eDLfbjV27dmlSTZnwzjvvYOHChfjyl78MQAlWduzYobmPy+UyTEefPn06PvvsM4wfP970eSdNmoRYLIZVq1bx9NPGjRvR3t6e1foA5f3FYjGEQiFDUDNx4kTs3r0bBw8exODBgwEoJd/Z8s477+C8887DN7/5TQBKsLNp0yZMnjw56+ciCILIJ4cNVoIaAFh4/GiUu/N/zCSjcJHz+9//HrFYDDNnzsRjjz2Gzz//HBs3bsTf/vY3bNiwAXa7ovrMnTsXX/jCFzB//ny8/PLL2LFjB1auXIkf/vCH+OijjzJ6rYqKCtx44424/vrr8fDDD2Pr1q1YvXo1li5diocffjjlYydMmIAnn3wSa9euxbp16/CNb3yDqxeM0aNH46233sLevXvR3NwMALjpppuwcuVKXHXVVVi7di02b96MZ555hhuFJ06ciDPOOAOXX3453n//faxatQr/+7//q1GpzJgzZw7uv/9+rFq1Cjt27MALL7yAH/zgBzj55JNRWVlpuP9pp52GcePGYcGCBfj444/xzjvv4Ec/+hEAZDX4dMKECVixYgVWrlyJzz//HJdffjkOHjyY8eMJgiAKBear8TrtWDh7TJ5Xo0BBTZEzbtw4rFmzBnPnzsXixYtx5JFHYubMmVi6dCluvPFG3H777QCUA+8LL7yAL37xi7jkkktw2GGH4etf/zp27tzJlYdMuP3223HLLbdgyZIlOPzww3HGGWfg+eefx5gxqf+gf/WrX6GmpgbHH388zjnnHMybNw/Tp0/X3OenP/0pduzYgXHjxvEeMdOmTcObb76JTZs24cQTT8TRRx+NW2+9FcOGDeOPW758OYYNG4aTTjoJX/nKV/Cd73wHDQ0NKdczb948PPzwwzj99NNx+OGH4+qrr8a8efPw+OOPm97fbrfj6aefRnd3N4455hj87//+L69+ymao5I9+9CNMnz4d8+bNw5w5czBkyBDMnz8/48cTBEEUCvOOGIKxg8rw/TMmoras5yn7XCLJmdYPlwCdnZ2oqqpCR0eH4Ww8FAph+/btGDNmDE0+JjLinXfewQknnIAtW7Zg3Lhx/fa69LdKEMRAI9XxWyT/CTCCKBKeeuoplJeXY8KECdiyZQuuvfZazJ49u18DGoIgCMIaCmoIIkO6urpw0003YdeuXRg0aBDmzp2LX/7yl/leFkEQBJGEghqCyJBvfetb+Na3vpXvZRAEQRAWkFGYIAiCIIiSgIIagiAIgiBKAgpqdAygYjCiSKG/UYIgCHMoqEnCWtsHAoE8r4QgUsP+RvUjLQiCIAY6ZBROYrfbUV1dzYc3+ny+rDrFEkRfI8syAoEAmpqaUF1dzbtFEwRBEAoU1AiwCcwssCGIQqS6ulozLZwgCIJQoKBGQJIkDB06FA0NDYhGo/leDkEYcDqdpNAQBEFYQEGNCXa7nQ4cBEEQBFFkkFGYIAiCIIiSgIIagiAIgiBKAgpqCIIgCIIoCQaUp4Y1Levs7MzzSgiCIAiCyBR23E7XfHRABTVdXV0AgMbGxjyvhCAIgiCIbOnq6kJVVZXl7ZI8gHquJxIJ7Nu3DxUVFXlprNfZ2YnGxkbs3r0blZWV/f76hQ59Pqmhzyc19Pmkhj4fa+izSU0hfD6yLKOrqwvDhg2DzWbtnBlQSo3NZsOIESPyvQxUVlbSFycF9Pmkhj6f1NDnkxr6fKyhzyY1+f58Uik0DDIKEwRBEARRElBQQxAEQRBESUBBTT/idrtx2223we1253spBQl9Pqmhzyc19Pmkhj4fa+izSU0xfT4DyihMEARBEETpQkoNQRAEQRAlAQU1BEEQBEGUBBTUEARBEARRElBQQxAEQRBESUBBTR4599xzMXLkSHg8HgwdOhQXX3wx9u3bl+9lFQQ7duzAt7/9bYwZMwZerxfjxo3Dbbfdhkgkku+lFQR33HEHjj/+ePh8PlRXV+d7OXnnvvvuw+jRo+HxeHDsscfigw8+yPeSCoa33noL55xzDoYNGwZJkvD000/ne0kFw5IlS3DMMcegoqICDQ0NmD9/PjZu3JjvZRUMy5Ytw7Rp03jTvS984Qt48cUX872slFBQk0dOPvlkPP7449i4cSP+9a9/YevWrTj//PPzvayCYMOGDUgkErj//vvx6aef4te//jX+8Ic/4Ac/+EG+l1YQRCIRXHDBBbjyyivzvZS889hjj+GGG27AbbfdhtWrV+PII4/EvHnz0NTUlO+lFQR+vx9HHnkk7rvvvnwvpeB48803sWjRIrz33ntYsWIFotEoTj/9dPj9/nwvrSAYMWIE7rrrLqxatQofffQRTjnlFJx33nn49NNP8700a2SiYHjmmWdkSZLkSCSS76UUJD//+c/lMWPG5HsZBcXy5cvlqqqqfC8jr8yaNUtetGgRvxyPx+Vhw4bJS5YsyeOqChMA8lNPPZXvZRQsTU1NMgD5zTffzPdSCpaamhr5wQcfzPcyLCGlpkBobW3FI488guOPPx5OpzPfyylIOjo6UFtbm+9lEAVEJBLBqlWrMHfuXH6dzWbD3Llz8e677+ZxZUQx0tHRAQC0z5gQj8fxj3/8A36/H1/4whfyvRxLKKjJMzfddBPKyspQV1eHXbt24Zlnnsn3kgqSLVu2YOnSpbj88svzvRSigGhubkY8HsfgwYM11w8ePBgHDhzI06qIYiSRSOC6667D7NmzMWXKlHwvp2D45JNPUF5eDrfbjSuuuAJPPfUUJk+enO9lWUJBTY65+eabIUlSyp8NGzbw+//f//0f1qxZg5dffhl2ux3f+ta3IJdwk+dsPx8A2Lt3L8444wxccMEFuOyyy/K08r6nJ58NQRC5YdGiRVi/fj3+8Y9/5HspBcXEiROxdu1avP/++7jyyiuxYMECfPbZZ/leliU0JiHHHDp0CC0tLSnvM3bsWLhcLsP1e/bsQWNjI1auXFnQ8l5vyPbz2bdvH+bMmYPjjjsODz30EGy20o3De/K389BDD+G6665De3t7H6+uMIlEIvD5fPjnP/+J+fPn8+sXLFiA9vZ2Uj51SJKEp556SvNZEcBVV12FZ555Bm+99RbGjBmT7+UUNHPnzsW4ceNw//3353sppjjyvYBSo76+HvX19T16bCKRAACEw+FcLqmgyObz2bt3L04++WTMmDEDy5cvL+mABujd385AxeVyYcaMGXj11Vf5gTqRSODVV1/FVVddld/FEQWPLMu4+uqr8dRTT+GNN96ggCYDEolEQR+jKKjJE++//z4+/PBDnHDCCaipqcHWrVtxyy23YNy4cSWr0mTD3r17MWfOHIwaNQr33HMPDh06xG8bMmRIHldWGOzatQutra3YtWsX4vE41q5dCwAYP348ysvL87u4fuaGG27AggULMHPmTMyaNQv33nsv/H4/LrnkknwvrSDo7u7Gli1b+OXt27dj7dq1qK2txciRI/O4svyzaNEiPProo3jmmWdQUVHBfVhVVVXwer15Xl3+Wbx4Mc4880yMHDkSXV1dePTRR/HGG2/gP//5T76XZk1+i68GLh9//LF88skny7W1tbLb7ZZHjx4tX3HFFfKePXvyvbSCYPny5TIA0x9ClhcsWGD62bz++uv5XlpeWLp0qTxy5EjZ5XLJs2bNkt977718L6lgeP31103/VhYsWJDvpeUdqz1m+fLl+V5aQXDppZfKo0aNkl0ul1xfXy+feuqp8ssvv5zvZaWEPDUEQRAEQZQEpW1SIAiCIAhiwEBBDUEQBEEQJQEFNQRBEARBlAQU1BAEQRAEURJQUEMQBEEQRElAQQ1BEARBECUBBTUEQRAEQZQEFNQQBEEQBFESUFBDEARBEERJQEENQRAEQRAlAQU1BEEULYcOHcKQIUNw55138utWrlwJl8uFV199NY8rIwgiH9DsJ4IgipoXXngB8+fPx8qVKzFx4kQcddRROO+88/CrX/0q30sjCKKfoaCGIIiiZ9GiRXjllVcwc+ZMfPLJJ/jwww/hdrvzvSyCIPoZCmoIgih6gsEgpkyZgt27d2PVqlWYOnVqvpdEEEQeIE8NQRBFz9atW7Fv3z4kEgns2LEj38shCCJPkFJDEERRE4lEMGvWLBx11FGYOHEi7r33XnzyySdoaGjI99IIguhnKKghCKKo+b//+z/885//xLp161BeXo6TTjoJVVVVeO655/K9NIIg+hlKPxEEUbS88cYbuPfee/HXv/4VlZWVsNls+Otf/4r//ve/WLZsWb6X9//t2DENAAAAgzD/rudiB2lVEIAzpwYASHBqAIAEUQMAJIgaACBB1AAACaIGAEgQNQBAgqgBABJEDQCQIGoAgARRAwAkiBoAIEHUAAAJA3HxE2cAoVcWAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(x, generated_signal, label='Generated Signal')\n",
        "plt.title('Generated Signal')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GduSJNrUP6Iz",
        "outputId": "590b18bc-d474-43d3-b78d-de04d8709ba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 6.017057   -3.7473211  -3.7699559   4.3745875   5.3567767   5.672146\n",
            " -0.621851    5.2058935   0.36788607 -1.742967    4.9365964   6.698516\n",
            "  7.051835   -1.4842271   6.384139    7.019278    0.23725533  6.3624587\n",
            "  8.096369   -0.7362393  -0.61982673  7.240876    7.2338147   7.361887\n",
            "  7.429068    7.4335566   7.3304367   7.2815127   7.841049   -1.3752413\n",
            "  6.6949      7.3483567   7.6016936  -0.7977345   6.76259    -0.8418369\n",
            "  6.685787   -0.46215492 -2.3471696   4.8104706  -2.2084258   4.7746844\n",
            "  4.5902066   5.499017    5.406509   -4.0420127   3.8682494  -2.786542\n",
            " -4.259643    2.847216   -3.2264     -4.1683874   2.2517438   4.195673\n",
            " -3.9107323   2.6988292  -3.0057852  -4.433805   -4.195891    3.3888464\n",
            "  4.8320446  -3.6099207  -4.1587825   3.7141874   4.6619763   4.8798666\n",
            " -2.315091    4.0869217  -1.2097412   4.6589003   5.7981763  -2.7762685\n",
            "  4.792074    5.9196234   5.894581    4.4992085  -3.2685914   4.033848\n",
            "  5.4157677   4.3265038  -3.9906242   2.8336687  -3.779333    2.5204003\n",
            " -3.5893624   2.5666068  -3.7748315  -5.453953   -4.8802834  -6.120629\n",
            " -0.02746868 -5.814045   -0.34526768  1.4918184   1.5594876   0.9056072\n",
            " -5.9896007  -6.0914087   0.35056803 -5.838146   -6.7631397  -6.5631137\n",
            " -7.3700905  -0.58121896  0.9095922  -7.5673265  -7.264607    0.19602539\n",
            "  0.8336879  -6.7978163   0.3699915  -6.2805443  -7.178951    0.42068774\n",
            " -6.2402344  -6.5689707  -6.4950795  -6.7916956  -7.2301345  -0.12150215\n",
            "  1.4262774  -6.9554453  -6.341923    1.2346855   2.3491526  -5.908304\n",
            "  1.8233559  -7.090719  ]\n"
          ]
        }
      ],
      "source": [
        "print(generated_signal)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}